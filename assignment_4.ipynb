{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "assignment_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnaZhuravleva/compling/blob/master/assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3UwKG8wtijR",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 4: Named entity recognition\n",
        "\n",
        "Create a model for Named Entity Recognition for dataset CoNLL 2002.  \n",
        "Your quality metric = f1_macro\n",
        "\n",
        "In your solution you should use: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost)   \n",
        "Tutorials:  \n",
        "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
        "1. https://github.com/catboost/tutorials \n",
        "\n",
        "More baselines you beat - better your score\n",
        " \n",
        "baseline 1 [3 points]: 0.0604      random labels  \n",
        "baseline 2 [5 points]: 0.3966      PoS features + logistic regression  \n",
        "baseline 3 [8 points]: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
        "\n",
        "[1 point] using feature engineering (creating features not presented in the baselines)\n",
        "\n",
        "! Your results must be reproducible. You should explicitly set all seeds random_states in yout model.  \n",
        "! Remember to use proper training pipeline.  \n",
        "\n",
        "bonus, think about:  \n",
        "1. [1 point] Why did we select f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeDaAn7htija",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn import model_selection\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV as GSCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "SEED=1337"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxuD9Y4wycV0",
        "colab_type": "code",
        "outputId": "8d6d961d-89d4-4523-b84a-aa2f1c82ae09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/Colab Notebooks/compling'\n",
        "sys.path.append(project_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR_kSfletijl",
        "colab_type": "code",
        "outputId": "80271a96-72a0-44cc-baa1-bb309db1248f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/compling/ner_short.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  next-next-pos next-next-word next-pos  ... sentence_idx           word tag\n",
              "0           NNS  demonstrators       IN  ...          1.0      Thousands   O\n",
              "1           VBP           have      NNS  ...          1.0             of   O\n",
              "2           VBN        marched      VBP  ...          1.0  demonstrators   O\n",
              "3            IN        through      VBN  ...          1.0           have   O\n",
              "4           NNP         London       IN  ...          1.0        marched   O\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMqIGNqltijz",
        "colab_type": "code",
        "outputId": "40b1ba6a-1da9-439d-fd86-29633dce51c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of sentences\n",
        "df.sentence_idx.max()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1500.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylGWcFQetikA",
        "colab_type": "code",
        "outputId": "1ad615e2-c040-441b-8e72-50a798ffc2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "# class distribution\n",
        "df.tag.value_counts(normalize=True )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        0.852828\n",
              "B-geo    0.027604\n",
              "B-gpe    0.020935\n",
              "B-org    0.020247\n",
              "I-per    0.017795\n",
              "B-tim    0.016927\n",
              "B-per    0.015312\n",
              "I-org    0.013937\n",
              "I-geo    0.005383\n",
              "I-tim    0.004247\n",
              "B-art    0.001376\n",
              "I-gpe    0.000837\n",
              "I-art    0.000748\n",
              "B-eve    0.000628\n",
              "I-eve    0.000508\n",
              "B-nat    0.000449\n",
              "I-nat    0.000239\n",
              "Name: tag, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaYi7mk2tikn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentence length\n",
        "tdf = df.set_index('sentence_idx')\n",
        "tdf['length'] = df.groupby('sentence_idx').sentence_idx.count()\n",
        "df = tdf.reset_index(drop=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oq3kcQ02E6m",
        "colab_type": "code",
        "outputId": "901620f5-1eee-412f-e93b-c78bac33d931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>have</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>NNS</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NNP</td>\n",
              "      <td>London</td>\n",
              "      <td>IN</td>\n",
              "      <td>through</td>\n",
              "      <td>VBN</td>\n",
              "      <td>VBP</td>\n",
              "      <td>NNS</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66869</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>NN</td>\n",
              "      <td>back</td>\n",
              "      <td>JJ</td>\n",
              "      <td>serious</td>\n",
              "      <td>DT</td>\n",
              "      <td>IN</td>\n",
              "      <td>VBN</td>\n",
              "      <td>hospitalized</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66870</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>NN</td>\n",
              "      <td>injury</td>\n",
              "      <td>NN</td>\n",
              "      <td>back</td>\n",
              "      <td>JJ</td>\n",
              "      <td>DT</td>\n",
              "      <td>IN</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>serious</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66871</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>NN</td>\n",
              "      <td>injury</td>\n",
              "      <td>NN</td>\n",
              "      <td>JJ</td>\n",
              "      <td>DT</td>\n",
              "      <td>a</td>\n",
              "      <td>serious</td>\n",
              "      <td>back</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66872</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>NN</td>\n",
              "      <td>NN</td>\n",
              "      <td>JJ</td>\n",
              "      <td>serious</td>\n",
              "      <td>back</td>\n",
              "      <td>injury</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66873</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>__END2__</td>\n",
              "      <td>__END2__</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>.</td>\n",
              "      <td>NN</td>\n",
              "      <td>NN</td>\n",
              "      <td>back</td>\n",
              "      <td>injury</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66874 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_idx next-next-pos next-next-word  ...           word tag length\n",
              "0               1.0           NNS  demonstrators  ...      Thousands   O     48\n",
              "1               1.0           VBP           have  ...             of   O     48\n",
              "2               1.0           VBN        marched  ...  demonstrators   O     48\n",
              "3               1.0            IN        through  ...           have   O     48\n",
              "4               1.0           NNP         London  ...        marched   O     48\n",
              "...             ...           ...            ...  ...            ...  ..    ...\n",
              "66869        1500.0            NN           back  ...              a   O     30\n",
              "66870        1500.0            NN         injury  ...        serious   O     30\n",
              "66871        1500.0             .              .  ...           back   O     30\n",
              "66872        1500.0      __END1__       __END1__  ...         injury   O     30\n",
              "66873        1500.0      __END2__       __END2__  ...              .   O     30\n",
              "\n",
              "[66874 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L29yM0dtilB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode categorial variables\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['pos'] = le.fit_transform(df.pos)\n",
        "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
        "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
        "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
        "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Fq7y_EtilT",
        "colab_type": "code",
        "outputId": "e50e987a-1477-4308-ed10-6d8baf70751c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        }
      },
      "source": [
        "df.head(30)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>28</td>\n",
              "      <td>to</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29</td>\n",
              "      <td>protest</td>\n",
              "      <td>28</td>\n",
              "      <td>to</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>through</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>protest</td>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>London</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "      <td>15</td>\n",
              "      <td>war</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>15</td>\n",
              "      <td>war</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>to</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>protest</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>and</td>\n",
              "      <td>16</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29</td>\n",
              "      <td>demand</td>\n",
              "      <td>5</td>\n",
              "      <td>and</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>war</td>\n",
              "      <td>in</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>demand</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>15</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>15</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>and</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>10</td>\n",
              "      <td>British</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>29</td>\n",
              "      <td>demand</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>troops</td>\n",
              "      <td>10</td>\n",
              "      <td>British</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>from</td>\n",
              "      <td>18</td>\n",
              "      <td>troops</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>of</td>\n",
              "      <td>British</td>\n",
              "      <td>B-gpe</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>that</td>\n",
              "      <td>9</td>\n",
              "      <td>from</td>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>British</td>\n",
              "      <td>troops</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.0</td>\n",
              "      <td>15</td>\n",
              "      <td>country</td>\n",
              "      <td>7</td>\n",
              "      <td>that</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>10</td>\n",
              "      <td>British</td>\n",
              "      <td>troops</td>\n",
              "      <td>from</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>.</td>\n",
              "      <td>15</td>\n",
              "      <td>country</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>troops</td>\n",
              "      <td>from</td>\n",
              "      <td>that</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.0</td>\n",
              "      <td>39</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>2</td>\n",
              "      <td>.</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>from</td>\n",
              "      <td>that</td>\n",
              "      <td>country</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "      <td>__END2__</td>\n",
              "      <td>39</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>that</td>\n",
              "      <td>country</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2.0</td>\n",
              "      <td>18</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Families</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2.0</td>\n",
              "      <td>32</td>\n",
              "      <td>killed</td>\n",
              "      <td>18</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Families</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2.0</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>32</td>\n",
              "      <td>killed</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Families</td>\n",
              "      <td>of</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.0</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>9</td>\n",
              "      <td>in</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>killed</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2.0</td>\n",
              "      <td>15</td>\n",
              "      <td>conflict</td>\n",
              "      <td>7</td>\n",
              "      <td>the</td>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>killed</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2.0</td>\n",
              "      <td>30</td>\n",
              "      <td>joined</td>\n",
              "      <td>15</td>\n",
              "      <td>conflict</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>killed</td>\n",
              "      <td>in</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentence_idx  next-next-pos next-next-word  ...           word    tag  length\n",
              "0            1.0             18  demonstrators  ...      Thousands      O      48\n",
              "1            1.0             33           have  ...             of      O      48\n",
              "2            1.0             32        marched  ...  demonstrators      O      48\n",
              "3            1.0              9        through  ...           have      O      48\n",
              "4            1.0             16         London  ...        marched      O      48\n",
              "5            1.0             28             to  ...        through      O      48\n",
              "6            1.0             29        protest  ...         London  B-geo      48\n",
              "7            1.0              7            the  ...             to      O      48\n",
              "8            1.0             15            war  ...        protest      O      48\n",
              "9            1.0              9             in  ...            the      O      48\n",
              "10           1.0             16           Iraq  ...            war      O      48\n",
              "11           1.0              5            and  ...             in      O      48\n",
              "12           1.0             29         demand  ...           Iraq  B-geo      48\n",
              "13           1.0              7            the  ...            and      O      48\n",
              "14           1.0             15     withdrawal  ...         demand      O      48\n",
              "15           1.0              9             of  ...            the      O      48\n",
              "16           1.0             10        British  ...     withdrawal      O      48\n",
              "17           1.0             18         troops  ...             of      O      48\n",
              "18           1.0              9           from  ...        British  B-gpe      48\n",
              "19           1.0              7           that  ...         troops      O      48\n",
              "20           1.0             15        country  ...           from      O      48\n",
              "21           1.0              2              .  ...           that      O      48\n",
              "22           1.0             39       __END1__  ...        country      O      48\n",
              "23           1.0             40       __END2__  ...              .      O      48\n",
              "24           2.0             18       soldiers  ...       Families      O      60\n",
              "25           2.0             32         killed  ...             of      O      60\n",
              "26           2.0              9             in  ...       soldiers      O      60\n",
              "27           2.0              7            the  ...         killed      O      60\n",
              "28           2.0             15       conflict  ...             in      O      60\n",
              "29           2.0             30         joined  ...            the      O      60\n",
              "\n",
              "[30 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mgrtoqltils",
        "colab_type": "code",
        "outputId": "1a04cd1a-1855-4e5e-9dc0-c4cbe042acad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# splitting\n",
        "y = LabelEncoder().fit_transform(df.tag)\n",
        "\n",
        "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
        "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp-4E_Q1timK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some wrappers to work with word2vec\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from collections import defaultdict\n",
        "\n",
        "   \n",
        "class Word2VecWrapper(TransformerMixin):\n",
        "    def __init__(self, window=5,negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
        "        self.window_ = window\n",
        "        self.negative_ = negative\n",
        "        self.size_ = size\n",
        "        self.iter_ = iter\n",
        "        self.is_cbow_ = is_cbow\n",
        "        self.w2v = None\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def get_size(self):\n",
        "        return self.size_\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        X: list of strings\n",
        "        \"\"\"\n",
        "        sentences_list = [x.split() for x in X]\n",
        "        self.w2v = Word2Vec(sentences_list, \n",
        "                            window=self.window_,\n",
        "                            negative=self.negative_, \n",
        "                            size=self.size_, \n",
        "                            iter=self.iter_,\n",
        "                            sg=not self.is_cbow_, seed=self.random_state)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def has(self, word):\n",
        "        return word in self.w2v\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        X: a list of words\n",
        "        \"\"\"\n",
        "        if self.w2v is None:\n",
        "            raise Exception('model not fitted')\n",
        "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A8dFug-tima",
        "colab_type": "code",
        "outputId": "b1f782c3-1d34-45aa-b477-61fd637b9306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "# here we exploit that word2vec is an unsupervised learning algorithm\n",
        "# so we can train it on the whole dataset (subject to discussion)\n",
        "\n",
        "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
        "\n",
        "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
        "w2v_cbow.fit(sentences_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.3 s, sys: 472 ms, total: 48.8 s\n",
            "Wall time: 27.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smdKbpCjtimo",
        "colab_type": "code",
        "outputId": "1a92ebf4-bda3-45cf-8622-829b5fe0c5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%%time\n",
        "# baseline 1 \n",
        "# random labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est',RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = SEED))\n",
        "   # ('est', DummyClassifier(random_state=SEED))\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.7425836587782345\n",
            "test 0.5863944082579811\n",
            "CPU times: user 2.54 s, sys: 16 ms, total: 2.56 s\n",
            "Wall time: 2.57 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME1iIxrjkHzy",
        "colab_type": "text"
      },
      "source": [
        "just try to use catboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kocIc6CGUH5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "25ca45f0-5cce-452a-c55a-88ba1fcd1d54"
      },
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "model = CatBoostClassifier()\n",
        "model.fit(df_train[columns], y_train)\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (0.20)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.3.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.17.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.6.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.6.0)\n",
            "0:\tlearn: 2.4460573\ttotal: 162ms\tremaining: 2m 41s\n",
            "1:\tlearn: 2.2030895\ttotal: 269ms\tremaining: 2m 14s\n",
            "2:\tlearn: 2.0229944\ttotal: 384ms\tremaining: 2m 7s\n",
            "3:\tlearn: 1.8784822\ttotal: 490ms\tremaining: 2m 2s\n",
            "4:\tlearn: 1.7702973\ttotal: 601ms\tremaining: 1m 59s\n",
            "5:\tlearn: 1.6688457\ttotal: 712ms\tremaining: 1m 58s\n",
            "6:\tlearn: 1.5809830\ttotal: 823ms\tremaining: 1m 56s\n",
            "7:\tlearn: 1.5035829\ttotal: 932ms\tremaining: 1m 55s\n",
            "8:\tlearn: 1.4357570\ttotal: 1.04s\tremaining: 1m 54s\n",
            "9:\tlearn: 1.3714008\ttotal: 1.15s\tremaining: 1m 54s\n",
            "10:\tlearn: 1.3148094\ttotal: 1.27s\tremaining: 1m 54s\n",
            "11:\tlearn: 1.2620485\ttotal: 1.38s\tremaining: 1m 53s\n",
            "12:\tlearn: 1.2137771\ttotal: 1.49s\tremaining: 1m 52s\n",
            "13:\tlearn: 1.1694000\ttotal: 1.59s\tremaining: 1m 52s\n",
            "14:\tlearn: 1.1300471\ttotal: 1.7s\tremaining: 1m 51s\n",
            "15:\tlearn: 1.0951468\ttotal: 1.81s\tremaining: 1m 51s\n",
            "16:\tlearn: 1.0594521\ttotal: 1.92s\tremaining: 1m 51s\n",
            "17:\tlearn: 1.0269822\ttotal: 2.03s\tremaining: 1m 50s\n",
            "18:\tlearn: 0.9960648\ttotal: 2.14s\tremaining: 1m 50s\n",
            "19:\tlearn: 0.9666449\ttotal: 2.25s\tremaining: 1m 50s\n",
            "20:\tlearn: 0.9387696\ttotal: 2.36s\tremaining: 1m 49s\n",
            "21:\tlearn: 0.9121022\ttotal: 2.46s\tremaining: 1m 49s\n",
            "22:\tlearn: 0.8880351\ttotal: 2.58s\tremaining: 1m 49s\n",
            "23:\tlearn: 0.8641290\ttotal: 2.69s\tremaining: 1m 49s\n",
            "24:\tlearn: 0.8420728\ttotal: 2.81s\tremaining: 1m 49s\n",
            "25:\tlearn: 0.8206969\ttotal: 2.92s\tremaining: 1m 49s\n",
            "26:\tlearn: 0.8008079\ttotal: 3.03s\tremaining: 1m 49s\n",
            "27:\tlearn: 0.7820199\ttotal: 3.13s\tremaining: 1m 48s\n",
            "28:\tlearn: 0.7638532\ttotal: 3.25s\tremaining: 1m 48s\n",
            "29:\tlearn: 0.7462900\ttotal: 3.35s\tremaining: 1m 48s\n",
            "30:\tlearn: 0.7298121\ttotal: 3.47s\tremaining: 1m 48s\n",
            "31:\tlearn: 0.7153342\ttotal: 3.58s\tremaining: 1m 48s\n",
            "32:\tlearn: 0.7000802\ttotal: 3.7s\tremaining: 1m 48s\n",
            "33:\tlearn: 0.6858977\ttotal: 3.81s\tremaining: 1m 48s\n",
            "34:\tlearn: 0.6728891\ttotal: 3.94s\tremaining: 1m 48s\n",
            "35:\tlearn: 0.6602576\ttotal: 4.05s\tremaining: 1m 48s\n",
            "36:\tlearn: 0.6479361\ttotal: 4.16s\tremaining: 1m 48s\n",
            "37:\tlearn: 0.6359528\ttotal: 4.27s\tremaining: 1m 48s\n",
            "38:\tlearn: 0.6247333\ttotal: 4.38s\tremaining: 1m 48s\n",
            "39:\tlearn: 0.6144485\ttotal: 4.49s\tremaining: 1m 47s\n",
            "40:\tlearn: 0.6038131\ttotal: 4.61s\tremaining: 1m 47s\n",
            "41:\tlearn: 0.5935370\ttotal: 4.72s\tremaining: 1m 47s\n",
            "42:\tlearn: 0.5834281\ttotal: 4.85s\tremaining: 1m 47s\n",
            "43:\tlearn: 0.5744902\ttotal: 4.96s\tremaining: 1m 47s\n",
            "44:\tlearn: 0.5659095\ttotal: 5.07s\tremaining: 1m 47s\n",
            "45:\tlearn: 0.5570285\ttotal: 5.18s\tremaining: 1m 47s\n",
            "46:\tlearn: 0.5487057\ttotal: 5.29s\tremaining: 1m 47s\n",
            "47:\tlearn: 0.5411450\ttotal: 5.4s\tremaining: 1m 47s\n",
            "48:\tlearn: 0.5329836\ttotal: 5.51s\tremaining: 1m 47s\n",
            "49:\tlearn: 0.5252470\ttotal: 5.63s\tremaining: 1m 46s\n",
            "50:\tlearn: 0.5175027\ttotal: 5.74s\tremaining: 1m 46s\n",
            "51:\tlearn: 0.5099057\ttotal: 5.85s\tremaining: 1m 46s\n",
            "52:\tlearn: 0.5028207\ttotal: 5.97s\tremaining: 1m 46s\n",
            "53:\tlearn: 0.4960244\ttotal: 6.08s\tremaining: 1m 46s\n",
            "54:\tlearn: 0.4896433\ttotal: 6.19s\tremaining: 1m 46s\n",
            "55:\tlearn: 0.4836272\ttotal: 6.3s\tremaining: 1m 46s\n",
            "56:\tlearn: 0.4779306\ttotal: 6.41s\tremaining: 1m 46s\n",
            "57:\tlearn: 0.4721840\ttotal: 6.52s\tremaining: 1m 45s\n",
            "58:\tlearn: 0.4663592\ttotal: 6.63s\tremaining: 1m 45s\n",
            "59:\tlearn: 0.4611542\ttotal: 6.74s\tremaining: 1m 45s\n",
            "60:\tlearn: 0.4558699\ttotal: 6.86s\tremaining: 1m 45s\n",
            "61:\tlearn: 0.4510924\ttotal: 6.97s\tremaining: 1m 45s\n",
            "62:\tlearn: 0.4471647\ttotal: 7.08s\tremaining: 1m 45s\n",
            "63:\tlearn: 0.4425058\ttotal: 7.18s\tremaining: 1m 45s\n",
            "64:\tlearn: 0.4387896\ttotal: 7.3s\tremaining: 1m 44s\n",
            "65:\tlearn: 0.4345112\ttotal: 7.4s\tremaining: 1m 44s\n",
            "66:\tlearn: 0.4303268\ttotal: 7.52s\tremaining: 1m 44s\n",
            "67:\tlearn: 0.4262701\ttotal: 7.63s\tremaining: 1m 44s\n",
            "68:\tlearn: 0.4226741\ttotal: 7.75s\tremaining: 1m 44s\n",
            "69:\tlearn: 0.4195387\ttotal: 7.86s\tremaining: 1m 44s\n",
            "70:\tlearn: 0.4158539\ttotal: 7.97s\tremaining: 1m 44s\n",
            "71:\tlearn: 0.4123522\ttotal: 8.07s\tremaining: 1m 44s\n",
            "72:\tlearn: 0.4092426\ttotal: 8.19s\tremaining: 1m 43s\n",
            "73:\tlearn: 0.4058269\ttotal: 8.29s\tremaining: 1m 43s\n",
            "74:\tlearn: 0.4021413\ttotal: 8.41s\tremaining: 1m 43s\n",
            "75:\tlearn: 0.3989073\ttotal: 8.51s\tremaining: 1m 43s\n",
            "76:\tlearn: 0.3955038\ttotal: 8.63s\tremaining: 1m 43s\n",
            "77:\tlearn: 0.3921515\ttotal: 8.73s\tremaining: 1m 43s\n",
            "78:\tlearn: 0.3891368\ttotal: 8.85s\tremaining: 1m 43s\n",
            "79:\tlearn: 0.3863552\ttotal: 8.96s\tremaining: 1m 42s\n",
            "80:\tlearn: 0.3836131\ttotal: 9.06s\tremaining: 1m 42s\n",
            "81:\tlearn: 0.3810958\ttotal: 9.17s\tremaining: 1m 42s\n",
            "82:\tlearn: 0.3786886\ttotal: 9.28s\tremaining: 1m 42s\n",
            "83:\tlearn: 0.3762685\ttotal: 9.39s\tremaining: 1m 42s\n",
            "84:\tlearn: 0.3740049\ttotal: 9.51s\tremaining: 1m 42s\n",
            "85:\tlearn: 0.3718416\ttotal: 9.61s\tremaining: 1m 42s\n",
            "86:\tlearn: 0.3693438\ttotal: 9.72s\tremaining: 1m 42s\n",
            "87:\tlearn: 0.3670248\ttotal: 9.83s\tremaining: 1m 41s\n",
            "88:\tlearn: 0.3644691\ttotal: 9.94s\tremaining: 1m 41s\n",
            "89:\tlearn: 0.3624361\ttotal: 10.1s\tremaining: 1m 41s\n",
            "90:\tlearn: 0.3600598\ttotal: 10.2s\tremaining: 1m 41s\n",
            "91:\tlearn: 0.3584711\ttotal: 10.3s\tremaining: 1m 41s\n",
            "92:\tlearn: 0.3565455\ttotal: 10.4s\tremaining: 1m 41s\n",
            "93:\tlearn: 0.3546973\ttotal: 10.5s\tremaining: 1m 41s\n",
            "94:\tlearn: 0.3524432\ttotal: 10.6s\tremaining: 1m 41s\n",
            "95:\tlearn: 0.3507756\ttotal: 10.7s\tremaining: 1m 40s\n",
            "96:\tlearn: 0.3485932\ttotal: 10.8s\tremaining: 1m 40s\n",
            "97:\tlearn: 0.3474538\ttotal: 10.9s\tremaining: 1m 40s\n",
            "98:\tlearn: 0.3456307\ttotal: 11.1s\tremaining: 1m 40s\n",
            "99:\tlearn: 0.3440786\ttotal: 11.2s\tremaining: 1m 40s\n",
            "100:\tlearn: 0.3425838\ttotal: 11.3s\tremaining: 1m 40s\n",
            "101:\tlearn: 0.3410038\ttotal: 11.4s\tremaining: 1m 40s\n",
            "102:\tlearn: 0.3393696\ttotal: 11.5s\tremaining: 1m 40s\n",
            "103:\tlearn: 0.3380492\ttotal: 11.6s\tremaining: 1m 40s\n",
            "104:\tlearn: 0.3369140\ttotal: 11.7s\tremaining: 1m 39s\n",
            "105:\tlearn: 0.3352247\ttotal: 11.8s\tremaining: 1m 39s\n",
            "106:\tlearn: 0.3339983\ttotal: 11.9s\tremaining: 1m 39s\n",
            "107:\tlearn: 0.3324193\ttotal: 12.1s\tremaining: 1m 39s\n",
            "108:\tlearn: 0.3311886\ttotal: 12.2s\tremaining: 1m 39s\n",
            "109:\tlearn: 0.3297412\ttotal: 12.3s\tremaining: 1m 39s\n",
            "110:\tlearn: 0.3285898\ttotal: 12.4s\tremaining: 1m 39s\n",
            "111:\tlearn: 0.3272883\ttotal: 12.5s\tremaining: 1m 39s\n",
            "112:\tlearn: 0.3260593\ttotal: 12.6s\tremaining: 1m 39s\n",
            "113:\tlearn: 0.3252076\ttotal: 12.7s\tremaining: 1m 38s\n",
            "114:\tlearn: 0.3239592\ttotal: 12.8s\tremaining: 1m 38s\n",
            "115:\tlearn: 0.3226201\ttotal: 12.9s\tremaining: 1m 38s\n",
            "116:\tlearn: 0.3215783\ttotal: 13.1s\tremaining: 1m 38s\n",
            "117:\tlearn: 0.3207937\ttotal: 13.2s\tremaining: 1m 38s\n",
            "118:\tlearn: 0.3195034\ttotal: 13.3s\tremaining: 1m 38s\n",
            "119:\tlearn: 0.3182213\ttotal: 13.4s\tremaining: 1m 38s\n",
            "120:\tlearn: 0.3174058\ttotal: 13.5s\tremaining: 1m 38s\n",
            "121:\tlearn: 0.3165387\ttotal: 13.6s\tremaining: 1m 37s\n",
            "122:\tlearn: 0.3156057\ttotal: 13.7s\tremaining: 1m 37s\n",
            "123:\tlearn: 0.3145297\ttotal: 13.8s\tremaining: 1m 37s\n",
            "124:\tlearn: 0.3135464\ttotal: 13.9s\tremaining: 1m 37s\n",
            "125:\tlearn: 0.3122770\ttotal: 14s\tremaining: 1m 37s\n",
            "126:\tlearn: 0.3110981\ttotal: 14.2s\tremaining: 1m 37s\n",
            "127:\tlearn: 0.3103665\ttotal: 14.3s\tremaining: 1m 37s\n",
            "128:\tlearn: 0.3095144\ttotal: 14.4s\tremaining: 1m 37s\n",
            "129:\tlearn: 0.3086818\ttotal: 14.5s\tremaining: 1m 37s\n",
            "130:\tlearn: 0.3078672\ttotal: 14.6s\tremaining: 1m 36s\n",
            "131:\tlearn: 0.3072867\ttotal: 14.7s\tremaining: 1m 36s\n",
            "132:\tlearn: 0.3063323\ttotal: 14.8s\tremaining: 1m 36s\n",
            "133:\tlearn: 0.3056416\ttotal: 15s\tremaining: 1m 36s\n",
            "134:\tlearn: 0.3051651\ttotal: 15.1s\tremaining: 1m 36s\n",
            "135:\tlearn: 0.3041242\ttotal: 15.2s\tremaining: 1m 36s\n",
            "136:\tlearn: 0.3032757\ttotal: 15.3s\tremaining: 1m 36s\n",
            "137:\tlearn: 0.3023446\ttotal: 15.4s\tremaining: 1m 36s\n",
            "138:\tlearn: 0.3018268\ttotal: 15.5s\tremaining: 1m 36s\n",
            "139:\tlearn: 0.3008120\ttotal: 15.6s\tremaining: 1m 35s\n",
            "140:\tlearn: 0.3002000\ttotal: 15.7s\tremaining: 1m 35s\n",
            "141:\tlearn: 0.2995207\ttotal: 15.8s\tremaining: 1m 35s\n",
            "142:\tlearn: 0.2990148\ttotal: 16s\tremaining: 1m 35s\n",
            "143:\tlearn: 0.2981827\ttotal: 16.1s\tremaining: 1m 35s\n",
            "144:\tlearn: 0.2974269\ttotal: 16.2s\tremaining: 1m 35s\n",
            "145:\tlearn: 0.2968930\ttotal: 16.3s\tremaining: 1m 35s\n",
            "146:\tlearn: 0.2963073\ttotal: 16.4s\tremaining: 1m 35s\n",
            "147:\tlearn: 0.2955117\ttotal: 16.5s\tremaining: 1m 35s\n",
            "148:\tlearn: 0.2950664\ttotal: 16.6s\tremaining: 1m 34s\n",
            "149:\tlearn: 0.2944806\ttotal: 16.7s\tremaining: 1m 34s\n",
            "150:\tlearn: 0.2939505\ttotal: 16.8s\tremaining: 1m 34s\n",
            "151:\tlearn: 0.2934917\ttotal: 17s\tremaining: 1m 34s\n",
            "152:\tlearn: 0.2928569\ttotal: 17.1s\tremaining: 1m 34s\n",
            "153:\tlearn: 0.2924461\ttotal: 17.2s\tremaining: 1m 34s\n",
            "154:\tlearn: 0.2916513\ttotal: 17.3s\tremaining: 1m 34s\n",
            "155:\tlearn: 0.2912066\ttotal: 17.4s\tremaining: 1m 34s\n",
            "156:\tlearn: 0.2906871\ttotal: 17.5s\tremaining: 1m 34s\n",
            "157:\tlearn: 0.2899702\ttotal: 17.6s\tremaining: 1m 33s\n",
            "158:\tlearn: 0.2892657\ttotal: 17.7s\tremaining: 1m 33s\n",
            "159:\tlearn: 0.2886203\ttotal: 17.8s\tremaining: 1m 33s\n",
            "160:\tlearn: 0.2881837\ttotal: 18s\tremaining: 1m 33s\n",
            "161:\tlearn: 0.2877298\ttotal: 18.1s\tremaining: 1m 33s\n",
            "162:\tlearn: 0.2870900\ttotal: 18.2s\tremaining: 1m 33s\n",
            "163:\tlearn: 0.2864675\ttotal: 18.3s\tremaining: 1m 33s\n",
            "164:\tlearn: 0.2860016\ttotal: 18.4s\tremaining: 1m 33s\n",
            "165:\tlearn: 0.2854488\ttotal: 18.5s\tremaining: 1m 32s\n",
            "166:\tlearn: 0.2848317\ttotal: 18.6s\tremaining: 1m 32s\n",
            "167:\tlearn: 0.2845090\ttotal: 18.7s\tremaining: 1m 32s\n",
            "168:\tlearn: 0.2842211\ttotal: 18.8s\tremaining: 1m 32s\n",
            "169:\tlearn: 0.2836179\ttotal: 19s\tremaining: 1m 32s\n",
            "170:\tlearn: 0.2830694\ttotal: 19.1s\tremaining: 1m 32s\n",
            "171:\tlearn: 0.2828113\ttotal: 19.2s\tremaining: 1m 32s\n",
            "172:\tlearn: 0.2824636\ttotal: 19.3s\tremaining: 1m 32s\n",
            "173:\tlearn: 0.2818633\ttotal: 19.4s\tremaining: 1m 32s\n",
            "174:\tlearn: 0.2815138\ttotal: 19.5s\tremaining: 1m 31s\n",
            "175:\tlearn: 0.2811509\ttotal: 19.6s\tremaining: 1m 31s\n",
            "176:\tlearn: 0.2807791\ttotal: 19.7s\tremaining: 1m 31s\n",
            "177:\tlearn: 0.2802990\ttotal: 19.9s\tremaining: 1m 31s\n",
            "178:\tlearn: 0.2799294\ttotal: 20s\tremaining: 1m 31s\n",
            "179:\tlearn: 0.2795900\ttotal: 20.1s\tremaining: 1m 31s\n",
            "180:\tlearn: 0.2792743\ttotal: 20.2s\tremaining: 1m 31s\n",
            "181:\tlearn: 0.2789144\ttotal: 20.3s\tremaining: 1m 31s\n",
            "182:\tlearn: 0.2786271\ttotal: 20.4s\tremaining: 1m 31s\n",
            "183:\tlearn: 0.2783441\ttotal: 20.5s\tremaining: 1m 30s\n",
            "184:\tlearn: 0.2779831\ttotal: 20.6s\tremaining: 1m 30s\n",
            "185:\tlearn: 0.2777588\ttotal: 20.7s\tremaining: 1m 30s\n",
            "186:\tlearn: 0.2773214\ttotal: 20.8s\tremaining: 1m 30s\n",
            "187:\tlearn: 0.2769639\ttotal: 21s\tremaining: 1m 30s\n",
            "188:\tlearn: 0.2765029\ttotal: 21.1s\tremaining: 1m 30s\n",
            "189:\tlearn: 0.2762530\ttotal: 21.2s\tremaining: 1m 30s\n",
            "190:\tlearn: 0.2757535\ttotal: 21.3s\tremaining: 1m 30s\n",
            "191:\tlearn: 0.2754585\ttotal: 21.4s\tremaining: 1m 30s\n",
            "192:\tlearn: 0.2750869\ttotal: 21.5s\tremaining: 1m 29s\n",
            "193:\tlearn: 0.2748388\ttotal: 21.6s\tremaining: 1m 29s\n",
            "194:\tlearn: 0.2745865\ttotal: 21.7s\tremaining: 1m 29s\n",
            "195:\tlearn: 0.2742248\ttotal: 21.8s\tremaining: 1m 29s\n",
            "196:\tlearn: 0.2739231\ttotal: 22s\tremaining: 1m 29s\n",
            "197:\tlearn: 0.2735599\ttotal: 22.1s\tremaining: 1m 29s\n",
            "198:\tlearn: 0.2733822\ttotal: 22.2s\tremaining: 1m 29s\n",
            "199:\tlearn: 0.2729624\ttotal: 22.3s\tremaining: 1m 29s\n",
            "200:\tlearn: 0.2727089\ttotal: 22.4s\tremaining: 1m 29s\n",
            "201:\tlearn: 0.2724489\ttotal: 22.5s\tremaining: 1m 28s\n",
            "202:\tlearn: 0.2720693\ttotal: 22.6s\tremaining: 1m 28s\n",
            "203:\tlearn: 0.2718471\ttotal: 22.7s\tremaining: 1m 28s\n",
            "204:\tlearn: 0.2715652\ttotal: 22.8s\tremaining: 1m 28s\n",
            "205:\tlearn: 0.2712567\ttotal: 22.9s\tremaining: 1m 28s\n",
            "206:\tlearn: 0.2709456\ttotal: 23.1s\tremaining: 1m 28s\n",
            "207:\tlearn: 0.2706146\ttotal: 23.2s\tremaining: 1m 28s\n",
            "208:\tlearn: 0.2703904\ttotal: 23.3s\tremaining: 1m 28s\n",
            "209:\tlearn: 0.2700640\ttotal: 23.4s\tremaining: 1m 28s\n",
            "210:\tlearn: 0.2698534\ttotal: 23.5s\tremaining: 1m 27s\n",
            "211:\tlearn: 0.2696317\ttotal: 23.6s\tremaining: 1m 27s\n",
            "212:\tlearn: 0.2694664\ttotal: 23.7s\tremaining: 1m 27s\n",
            "213:\tlearn: 0.2691955\ttotal: 23.8s\tremaining: 1m 27s\n",
            "214:\tlearn: 0.2687101\ttotal: 24s\tremaining: 1m 27s\n",
            "215:\tlearn: 0.2684798\ttotal: 24.1s\tremaining: 1m 27s\n",
            "216:\tlearn: 0.2682348\ttotal: 24.2s\tremaining: 1m 27s\n",
            "217:\tlearn: 0.2678995\ttotal: 24.3s\tremaining: 1m 27s\n",
            "218:\tlearn: 0.2676524\ttotal: 24.4s\tremaining: 1m 27s\n",
            "219:\tlearn: 0.2674260\ttotal: 24.5s\tremaining: 1m 26s\n",
            "220:\tlearn: 0.2671623\ttotal: 24.7s\tremaining: 1m 26s\n",
            "221:\tlearn: 0.2667754\ttotal: 24.8s\tremaining: 1m 26s\n",
            "222:\tlearn: 0.2663508\ttotal: 24.9s\tremaining: 1m 26s\n",
            "223:\tlearn: 0.2660571\ttotal: 25s\tremaining: 1m 26s\n",
            "224:\tlearn: 0.2658057\ttotal: 25.1s\tremaining: 1m 26s\n",
            "225:\tlearn: 0.2656198\ttotal: 25.2s\tremaining: 1m 26s\n",
            "226:\tlearn: 0.2654771\ttotal: 25.3s\tremaining: 1m 26s\n",
            "227:\tlearn: 0.2652513\ttotal: 25.4s\tremaining: 1m 26s\n",
            "228:\tlearn: 0.2650344\ttotal: 25.5s\tremaining: 1m 25s\n",
            "229:\tlearn: 0.2648339\ttotal: 25.6s\tremaining: 1m 25s\n",
            "230:\tlearn: 0.2646234\ttotal: 25.8s\tremaining: 1m 25s\n",
            "231:\tlearn: 0.2643632\ttotal: 25.9s\tremaining: 1m 25s\n",
            "232:\tlearn: 0.2640255\ttotal: 26s\tremaining: 1m 25s\n",
            "233:\tlearn: 0.2638771\ttotal: 26.1s\tremaining: 1m 25s\n",
            "234:\tlearn: 0.2636297\ttotal: 26.2s\tremaining: 1m 25s\n",
            "235:\tlearn: 0.2633318\ttotal: 26.3s\tremaining: 1m 25s\n",
            "236:\tlearn: 0.2631122\ttotal: 26.4s\tremaining: 1m 25s\n",
            "237:\tlearn: 0.2629364\ttotal: 26.5s\tremaining: 1m 24s\n",
            "238:\tlearn: 0.2627512\ttotal: 26.7s\tremaining: 1m 24s\n",
            "239:\tlearn: 0.2626151\ttotal: 26.8s\tremaining: 1m 24s\n",
            "240:\tlearn: 0.2623866\ttotal: 26.9s\tremaining: 1m 24s\n",
            "241:\tlearn: 0.2621345\ttotal: 27s\tremaining: 1m 24s\n",
            "242:\tlearn: 0.2619963\ttotal: 27.1s\tremaining: 1m 24s\n",
            "243:\tlearn: 0.2617724\ttotal: 27.2s\tremaining: 1m 24s\n",
            "244:\tlearn: 0.2616007\ttotal: 27.3s\tremaining: 1m 24s\n",
            "245:\tlearn: 0.2613317\ttotal: 27.4s\tremaining: 1m 24s\n",
            "246:\tlearn: 0.2611739\ttotal: 27.5s\tremaining: 1m 23s\n",
            "247:\tlearn: 0.2609469\ttotal: 27.7s\tremaining: 1m 23s\n",
            "248:\tlearn: 0.2608329\ttotal: 27.8s\tremaining: 1m 23s\n",
            "249:\tlearn: 0.2606423\ttotal: 27.9s\tremaining: 1m 23s\n",
            "250:\tlearn: 0.2604865\ttotal: 28s\tremaining: 1m 23s\n",
            "251:\tlearn: 0.2602216\ttotal: 28.1s\tremaining: 1m 23s\n",
            "252:\tlearn: 0.2600846\ttotal: 28.2s\tremaining: 1m 23s\n",
            "253:\tlearn: 0.2599130\ttotal: 28.3s\tremaining: 1m 23s\n",
            "254:\tlearn: 0.2596169\ttotal: 28.4s\tremaining: 1m 23s\n",
            "255:\tlearn: 0.2594229\ttotal: 28.6s\tremaining: 1m 22s\n",
            "256:\tlearn: 0.2593545\ttotal: 28.7s\tremaining: 1m 22s\n",
            "257:\tlearn: 0.2591719\ttotal: 28.8s\tremaining: 1m 22s\n",
            "258:\tlearn: 0.2590081\ttotal: 28.9s\tremaining: 1m 22s\n",
            "259:\tlearn: 0.2588868\ttotal: 29s\tremaining: 1m 22s\n",
            "260:\tlearn: 0.2587310\ttotal: 29.1s\tremaining: 1m 22s\n",
            "261:\tlearn: 0.2585444\ttotal: 29.2s\tremaining: 1m 22s\n",
            "262:\tlearn: 0.2584308\ttotal: 29.3s\tremaining: 1m 22s\n",
            "263:\tlearn: 0.2582507\ttotal: 29.4s\tremaining: 1m 22s\n",
            "264:\tlearn: 0.2581214\ttotal: 29.6s\tremaining: 1m 21s\n",
            "265:\tlearn: 0.2579340\ttotal: 29.7s\tremaining: 1m 21s\n",
            "266:\tlearn: 0.2578052\ttotal: 29.8s\tremaining: 1m 21s\n",
            "267:\tlearn: 0.2577013\ttotal: 29.9s\tremaining: 1m 21s\n",
            "268:\tlearn: 0.2574881\ttotal: 30s\tremaining: 1m 21s\n",
            "269:\tlearn: 0.2573723\ttotal: 30.1s\tremaining: 1m 21s\n",
            "270:\tlearn: 0.2572381\ttotal: 30.2s\tremaining: 1m 21s\n",
            "271:\tlearn: 0.2570818\ttotal: 30.3s\tremaining: 1m 21s\n",
            "272:\tlearn: 0.2569402\ttotal: 30.4s\tremaining: 1m 21s\n",
            "273:\tlearn: 0.2567266\ttotal: 30.6s\tremaining: 1m 20s\n",
            "274:\tlearn: 0.2565959\ttotal: 30.7s\tremaining: 1m 20s\n",
            "275:\tlearn: 0.2564263\ttotal: 30.8s\tremaining: 1m 20s\n",
            "276:\tlearn: 0.2561981\ttotal: 30.9s\tremaining: 1m 20s\n",
            "277:\tlearn: 0.2560400\ttotal: 31s\tremaining: 1m 20s\n",
            "278:\tlearn: 0.2558828\ttotal: 31.1s\tremaining: 1m 20s\n",
            "279:\tlearn: 0.2557577\ttotal: 31.2s\tremaining: 1m 20s\n",
            "280:\tlearn: 0.2555692\ttotal: 31.3s\tremaining: 1m 20s\n",
            "281:\tlearn: 0.2554719\ttotal: 31.4s\tremaining: 1m 20s\n",
            "282:\tlearn: 0.2553270\ttotal: 31.5s\tremaining: 1m 19s\n",
            "283:\tlearn: 0.2551036\ttotal: 31.7s\tremaining: 1m 19s\n",
            "284:\tlearn: 0.2548498\ttotal: 31.8s\tremaining: 1m 19s\n",
            "285:\tlearn: 0.2547070\ttotal: 31.9s\tremaining: 1m 19s\n",
            "286:\tlearn: 0.2545848\ttotal: 32s\tremaining: 1m 19s\n",
            "287:\tlearn: 0.2544945\ttotal: 32.1s\tremaining: 1m 19s\n",
            "288:\tlearn: 0.2542838\ttotal: 32.2s\tremaining: 1m 19s\n",
            "289:\tlearn: 0.2542069\ttotal: 32.3s\tremaining: 1m 19s\n",
            "290:\tlearn: 0.2540994\ttotal: 32.4s\tremaining: 1m 19s\n",
            "291:\tlearn: 0.2539251\ttotal: 32.5s\tremaining: 1m 18s\n",
            "292:\tlearn: 0.2537405\ttotal: 32.7s\tremaining: 1m 18s\n",
            "293:\tlearn: 0.2535712\ttotal: 32.8s\tremaining: 1m 18s\n",
            "294:\tlearn: 0.2534403\ttotal: 32.9s\tremaining: 1m 18s\n",
            "295:\tlearn: 0.2533479\ttotal: 33s\tremaining: 1m 18s\n",
            "296:\tlearn: 0.2531272\ttotal: 33.1s\tremaining: 1m 18s\n",
            "297:\tlearn: 0.2530021\ttotal: 33.2s\tremaining: 1m 18s\n",
            "298:\tlearn: 0.2528688\ttotal: 33.3s\tremaining: 1m 18s\n",
            "299:\tlearn: 0.2526967\ttotal: 33.4s\tremaining: 1m 18s\n",
            "300:\tlearn: 0.2525563\ttotal: 33.5s\tremaining: 1m 17s\n",
            "301:\tlearn: 0.2524444\ttotal: 33.6s\tremaining: 1m 17s\n",
            "302:\tlearn: 0.2523524\ttotal: 33.8s\tremaining: 1m 17s\n",
            "303:\tlearn: 0.2521536\ttotal: 33.9s\tremaining: 1m 17s\n",
            "304:\tlearn: 0.2520374\ttotal: 34s\tremaining: 1m 17s\n",
            "305:\tlearn: 0.2518615\ttotal: 34.1s\tremaining: 1m 17s\n",
            "306:\tlearn: 0.2517510\ttotal: 34.2s\tremaining: 1m 17s\n",
            "307:\tlearn: 0.2516191\ttotal: 34.3s\tremaining: 1m 17s\n",
            "308:\tlearn: 0.2515071\ttotal: 34.4s\tremaining: 1m 17s\n",
            "309:\tlearn: 0.2513693\ttotal: 34.5s\tremaining: 1m 16s\n",
            "310:\tlearn: 0.2512657\ttotal: 34.7s\tremaining: 1m 16s\n",
            "311:\tlearn: 0.2509991\ttotal: 34.8s\tremaining: 1m 16s\n",
            "312:\tlearn: 0.2507922\ttotal: 34.9s\tremaining: 1m 16s\n",
            "313:\tlearn: 0.2505361\ttotal: 35s\tremaining: 1m 16s\n",
            "314:\tlearn: 0.2504335\ttotal: 35.1s\tremaining: 1m 16s\n",
            "315:\tlearn: 0.2502982\ttotal: 35.2s\tremaining: 1m 16s\n",
            "316:\tlearn: 0.2502059\ttotal: 35.3s\tremaining: 1m 16s\n",
            "317:\tlearn: 0.2500509\ttotal: 35.5s\tremaining: 1m 16s\n",
            "318:\tlearn: 0.2498936\ttotal: 35.6s\tremaining: 1m 15s\n",
            "319:\tlearn: 0.2497387\ttotal: 35.7s\tremaining: 1m 15s\n",
            "320:\tlearn: 0.2496291\ttotal: 35.8s\tremaining: 1m 15s\n",
            "321:\tlearn: 0.2495136\ttotal: 35.9s\tremaining: 1m 15s\n",
            "322:\tlearn: 0.2494048\ttotal: 36s\tremaining: 1m 15s\n",
            "323:\tlearn: 0.2493581\ttotal: 36.1s\tremaining: 1m 15s\n",
            "324:\tlearn: 0.2492675\ttotal: 36.2s\tremaining: 1m 15s\n",
            "325:\tlearn: 0.2491262\ttotal: 36.3s\tremaining: 1m 15s\n",
            "326:\tlearn: 0.2489954\ttotal: 36.5s\tremaining: 1m 15s\n",
            "327:\tlearn: 0.2488668\ttotal: 36.6s\tremaining: 1m 14s\n",
            "328:\tlearn: 0.2487698\ttotal: 36.7s\tremaining: 1m 14s\n",
            "329:\tlearn: 0.2485338\ttotal: 36.8s\tremaining: 1m 14s\n",
            "330:\tlearn: 0.2483927\ttotal: 36.9s\tremaining: 1m 14s\n",
            "331:\tlearn: 0.2481833\ttotal: 37s\tremaining: 1m 14s\n",
            "332:\tlearn: 0.2480648\ttotal: 37.1s\tremaining: 1m 14s\n",
            "333:\tlearn: 0.2478353\ttotal: 37.2s\tremaining: 1m 14s\n",
            "334:\tlearn: 0.2477537\ttotal: 37.3s\tremaining: 1m 14s\n",
            "335:\tlearn: 0.2475630\ttotal: 37.5s\tremaining: 1m 14s\n",
            "336:\tlearn: 0.2474462\ttotal: 37.6s\tremaining: 1m 13s\n",
            "337:\tlearn: 0.2473055\ttotal: 37.7s\tremaining: 1m 13s\n",
            "338:\tlearn: 0.2471777\ttotal: 37.8s\tremaining: 1m 13s\n",
            "339:\tlearn: 0.2469866\ttotal: 37.9s\tremaining: 1m 13s\n",
            "340:\tlearn: 0.2468919\ttotal: 38s\tremaining: 1m 13s\n",
            "341:\tlearn: 0.2467738\ttotal: 38.1s\tremaining: 1m 13s\n",
            "342:\tlearn: 0.2465504\ttotal: 38.2s\tremaining: 1m 13s\n",
            "343:\tlearn: 0.2464547\ttotal: 38.3s\tremaining: 1m 13s\n",
            "344:\tlearn: 0.2463500\ttotal: 38.5s\tremaining: 1m 13s\n",
            "345:\tlearn: 0.2462925\ttotal: 38.6s\tremaining: 1m 12s\n",
            "346:\tlearn: 0.2462000\ttotal: 38.7s\tremaining: 1m 12s\n",
            "347:\tlearn: 0.2460401\ttotal: 38.8s\tremaining: 1m 12s\n",
            "348:\tlearn: 0.2458970\ttotal: 38.9s\tremaining: 1m 12s\n",
            "349:\tlearn: 0.2457874\ttotal: 39s\tremaining: 1m 12s\n",
            "350:\tlearn: 0.2455861\ttotal: 39.1s\tremaining: 1m 12s\n",
            "351:\tlearn: 0.2455091\ttotal: 39.2s\tremaining: 1m 12s\n",
            "352:\tlearn: 0.2454174\ttotal: 39.3s\tremaining: 1m 12s\n",
            "353:\tlearn: 0.2453154\ttotal: 39.5s\tremaining: 1m 11s\n",
            "354:\tlearn: 0.2452198\ttotal: 39.6s\tremaining: 1m 11s\n",
            "355:\tlearn: 0.2451327\ttotal: 39.7s\tremaining: 1m 11s\n",
            "356:\tlearn: 0.2450220\ttotal: 39.8s\tremaining: 1m 11s\n",
            "357:\tlearn: 0.2449392\ttotal: 39.9s\tremaining: 1m 11s\n",
            "358:\tlearn: 0.2448269\ttotal: 40s\tremaining: 1m 11s\n",
            "359:\tlearn: 0.2447301\ttotal: 40.1s\tremaining: 1m 11s\n",
            "360:\tlearn: 0.2445880\ttotal: 40.2s\tremaining: 1m 11s\n",
            "361:\tlearn: 0.2444849\ttotal: 40.3s\tremaining: 1m 11s\n",
            "362:\tlearn: 0.2444095\ttotal: 40.5s\tremaining: 1m 11s\n",
            "363:\tlearn: 0.2443385\ttotal: 40.6s\tremaining: 1m 10s\n",
            "364:\tlearn: 0.2442250\ttotal: 40.7s\tremaining: 1m 10s\n",
            "365:\tlearn: 0.2441500\ttotal: 40.8s\tremaining: 1m 10s\n",
            "366:\tlearn: 0.2440661\ttotal: 40.9s\tremaining: 1m 10s\n",
            "367:\tlearn: 0.2439232\ttotal: 41s\tremaining: 1m 10s\n",
            "368:\tlearn: 0.2437730\ttotal: 41.1s\tremaining: 1m 10s\n",
            "369:\tlearn: 0.2436182\ttotal: 41.2s\tremaining: 1m 10s\n",
            "370:\tlearn: 0.2435047\ttotal: 41.3s\tremaining: 1m 10s\n",
            "371:\tlearn: 0.2434125\ttotal: 41.5s\tremaining: 1m 9s\n",
            "372:\tlearn: 0.2433545\ttotal: 41.6s\tremaining: 1m 9s\n",
            "373:\tlearn: 0.2431540\ttotal: 41.7s\tremaining: 1m 9s\n",
            "374:\tlearn: 0.2429597\ttotal: 41.8s\tremaining: 1m 9s\n",
            "375:\tlearn: 0.2428641\ttotal: 41.9s\tremaining: 1m 9s\n",
            "376:\tlearn: 0.2427929\ttotal: 42s\tremaining: 1m 9s\n",
            "377:\tlearn: 0.2427377\ttotal: 42.1s\tremaining: 1m 9s\n",
            "378:\tlearn: 0.2426631\ttotal: 42.2s\tremaining: 1m 9s\n",
            "379:\tlearn: 0.2425747\ttotal: 42.3s\tremaining: 1m 9s\n",
            "380:\tlearn: 0.2424197\ttotal: 42.5s\tremaining: 1m 8s\n",
            "381:\tlearn: 0.2423562\ttotal: 42.6s\tremaining: 1m 8s\n",
            "382:\tlearn: 0.2422698\ttotal: 42.7s\tremaining: 1m 8s\n",
            "383:\tlearn: 0.2421306\ttotal: 42.8s\tremaining: 1m 8s\n",
            "384:\tlearn: 0.2420277\ttotal: 42.9s\tremaining: 1m 8s\n",
            "385:\tlearn: 0.2419372\ttotal: 43s\tremaining: 1m 8s\n",
            "386:\tlearn: 0.2418384\ttotal: 43.1s\tremaining: 1m 8s\n",
            "387:\tlearn: 0.2416660\ttotal: 43.2s\tremaining: 1m 8s\n",
            "388:\tlearn: 0.2415344\ttotal: 43.3s\tremaining: 1m 8s\n",
            "389:\tlearn: 0.2413933\ttotal: 43.5s\tremaining: 1m 7s\n",
            "390:\tlearn: 0.2412505\ttotal: 43.6s\tremaining: 1m 7s\n",
            "391:\tlearn: 0.2411318\ttotal: 43.7s\tremaining: 1m 7s\n",
            "392:\tlearn: 0.2410639\ttotal: 43.8s\tremaining: 1m 7s\n",
            "393:\tlearn: 0.2409202\ttotal: 43.9s\tremaining: 1m 7s\n",
            "394:\tlearn: 0.2408413\ttotal: 44s\tremaining: 1m 7s\n",
            "395:\tlearn: 0.2407069\ttotal: 44.1s\tremaining: 1m 7s\n",
            "396:\tlearn: 0.2405787\ttotal: 44.2s\tremaining: 1m 7s\n",
            "397:\tlearn: 0.2405023\ttotal: 44.3s\tremaining: 1m 7s\n",
            "398:\tlearn: 0.2404025\ttotal: 44.4s\tremaining: 1m 6s\n",
            "399:\tlearn: 0.2402347\ttotal: 44.6s\tremaining: 1m 6s\n",
            "400:\tlearn: 0.2401463\ttotal: 44.7s\tremaining: 1m 6s\n",
            "401:\tlearn: 0.2400082\ttotal: 44.8s\tremaining: 1m 6s\n",
            "402:\tlearn: 0.2398279\ttotal: 44.9s\tremaining: 1m 6s\n",
            "403:\tlearn: 0.2396348\ttotal: 45s\tremaining: 1m 6s\n",
            "404:\tlearn: 0.2395582\ttotal: 45.1s\tremaining: 1m 6s\n",
            "405:\tlearn: 0.2394218\ttotal: 45.2s\tremaining: 1m 6s\n",
            "406:\tlearn: 0.2393173\ttotal: 45.4s\tremaining: 1m 6s\n",
            "407:\tlearn: 0.2391104\ttotal: 45.5s\tremaining: 1m 5s\n",
            "408:\tlearn: 0.2390315\ttotal: 45.6s\tremaining: 1m 5s\n",
            "409:\tlearn: 0.2389291\ttotal: 45.7s\tremaining: 1m 5s\n",
            "410:\tlearn: 0.2388726\ttotal: 45.8s\tremaining: 1m 5s\n",
            "411:\tlearn: 0.2387900\ttotal: 45.9s\tremaining: 1m 5s\n",
            "412:\tlearn: 0.2386504\ttotal: 46s\tremaining: 1m 5s\n",
            "413:\tlearn: 0.2385658\ttotal: 46.1s\tremaining: 1m 5s\n",
            "414:\tlearn: 0.2384447\ttotal: 46.3s\tremaining: 1m 5s\n",
            "415:\tlearn: 0.2383192\ttotal: 46.4s\tremaining: 1m 5s\n",
            "416:\tlearn: 0.2382119\ttotal: 46.5s\tremaining: 1m 4s\n",
            "417:\tlearn: 0.2381433\ttotal: 46.6s\tremaining: 1m 4s\n",
            "418:\tlearn: 0.2380680\ttotal: 46.7s\tremaining: 1m 4s\n",
            "419:\tlearn: 0.2379277\ttotal: 46.8s\tremaining: 1m 4s\n",
            "420:\tlearn: 0.2378476\ttotal: 46.9s\tremaining: 1m 4s\n",
            "421:\tlearn: 0.2377549\ttotal: 47s\tremaining: 1m 4s\n",
            "422:\tlearn: 0.2375853\ttotal: 47.1s\tremaining: 1m 4s\n",
            "423:\tlearn: 0.2375250\ttotal: 47.3s\tremaining: 1m 4s\n",
            "424:\tlearn: 0.2374166\ttotal: 47.4s\tremaining: 1m 4s\n",
            "425:\tlearn: 0.2372635\ttotal: 47.5s\tremaining: 1m 3s\n",
            "426:\tlearn: 0.2371447\ttotal: 47.6s\tremaining: 1m 3s\n",
            "427:\tlearn: 0.2370382\ttotal: 47.7s\tremaining: 1m 3s\n",
            "428:\tlearn: 0.2369409\ttotal: 47.8s\tremaining: 1m 3s\n",
            "429:\tlearn: 0.2368662\ttotal: 47.9s\tremaining: 1m 3s\n",
            "430:\tlearn: 0.2367979\ttotal: 48s\tremaining: 1m 3s\n",
            "431:\tlearn: 0.2367181\ttotal: 48.1s\tremaining: 1m 3s\n",
            "432:\tlearn: 0.2366376\ttotal: 48.3s\tremaining: 1m 3s\n",
            "433:\tlearn: 0.2365283\ttotal: 48.4s\tremaining: 1m 3s\n",
            "434:\tlearn: 0.2364510\ttotal: 48.5s\tremaining: 1m 2s\n",
            "435:\tlearn: 0.2363525\ttotal: 48.6s\tremaining: 1m 2s\n",
            "436:\tlearn: 0.2361893\ttotal: 48.7s\tremaining: 1m 2s\n",
            "437:\tlearn: 0.2360855\ttotal: 48.8s\tremaining: 1m 2s\n",
            "438:\tlearn: 0.2359621\ttotal: 48.9s\tremaining: 1m 2s\n",
            "439:\tlearn: 0.2358553\ttotal: 49s\tremaining: 1m 2s\n",
            "440:\tlearn: 0.2357892\ttotal: 49.1s\tremaining: 1m 2s\n",
            "441:\tlearn: 0.2356826\ttotal: 49.3s\tremaining: 1m 2s\n",
            "442:\tlearn: 0.2355900\ttotal: 49.4s\tremaining: 1m 2s\n",
            "443:\tlearn: 0.2354756\ttotal: 49.5s\tremaining: 1m 1s\n",
            "444:\tlearn: 0.2353869\ttotal: 49.6s\tremaining: 1m 1s\n",
            "445:\tlearn: 0.2353225\ttotal: 49.7s\tremaining: 1m 1s\n",
            "446:\tlearn: 0.2352707\ttotal: 49.8s\tremaining: 1m 1s\n",
            "447:\tlearn: 0.2352174\ttotal: 49.9s\tremaining: 1m 1s\n",
            "448:\tlearn: 0.2351549\ttotal: 50s\tremaining: 1m 1s\n",
            "449:\tlearn: 0.2350242\ttotal: 50.1s\tremaining: 1m 1s\n",
            "450:\tlearn: 0.2349092\ttotal: 50.3s\tremaining: 1m 1s\n",
            "451:\tlearn: 0.2348335\ttotal: 50.4s\tremaining: 1m 1s\n",
            "452:\tlearn: 0.2347657\ttotal: 50.5s\tremaining: 1m\n",
            "453:\tlearn: 0.2346610\ttotal: 50.6s\tremaining: 1m\n",
            "454:\tlearn: 0.2346110\ttotal: 50.7s\tremaining: 1m\n",
            "455:\tlearn: 0.2345523\ttotal: 50.8s\tremaining: 1m\n",
            "456:\tlearn: 0.2344691\ttotal: 50.9s\tremaining: 1m\n",
            "457:\tlearn: 0.2344276\ttotal: 51s\tremaining: 1m\n",
            "458:\tlearn: 0.2343206\ttotal: 51.2s\tremaining: 1m\n",
            "459:\tlearn: 0.2342501\ttotal: 51.3s\tremaining: 1m\n",
            "460:\tlearn: 0.2341981\ttotal: 51.4s\tremaining: 1m\n",
            "461:\tlearn: 0.2341353\ttotal: 51.5s\tremaining: 60s\n",
            "462:\tlearn: 0.2340444\ttotal: 51.6s\tremaining: 59.9s\n",
            "463:\tlearn: 0.2339411\ttotal: 51.7s\tremaining: 59.7s\n",
            "464:\tlearn: 0.2338507\ttotal: 51.8s\tremaining: 59.6s\n",
            "465:\tlearn: 0.2337763\ttotal: 51.9s\tremaining: 59.5s\n",
            "466:\tlearn: 0.2336228\ttotal: 52s\tremaining: 59.4s\n",
            "467:\tlearn: 0.2335278\ttotal: 52.2s\tremaining: 59.3s\n",
            "468:\tlearn: 0.2333960\ttotal: 52.3s\tremaining: 59.2s\n",
            "469:\tlearn: 0.2333054\ttotal: 52.4s\tremaining: 59.1s\n",
            "470:\tlearn: 0.2332161\ttotal: 52.5s\tremaining: 59s\n",
            "471:\tlearn: 0.2331425\ttotal: 52.6s\tremaining: 58.9s\n",
            "472:\tlearn: 0.2330614\ttotal: 52.7s\tremaining: 58.7s\n",
            "473:\tlearn: 0.2329722\ttotal: 52.8s\tremaining: 58.6s\n",
            "474:\tlearn: 0.2329004\ttotal: 53s\tremaining: 58.5s\n",
            "475:\tlearn: 0.2328466\ttotal: 53.1s\tremaining: 58.4s\n",
            "476:\tlearn: 0.2326927\ttotal: 53.2s\tremaining: 58.3s\n",
            "477:\tlearn: 0.2326106\ttotal: 53.3s\tremaining: 58.2s\n",
            "478:\tlearn: 0.2325415\ttotal: 53.4s\tremaining: 58.1s\n",
            "479:\tlearn: 0.2324783\ttotal: 53.5s\tremaining: 58s\n",
            "480:\tlearn: 0.2324051\ttotal: 53.6s\tremaining: 57.9s\n",
            "481:\tlearn: 0.2323306\ttotal: 53.7s\tremaining: 57.7s\n",
            "482:\tlearn: 0.2322361\ttotal: 53.9s\tremaining: 57.6s\n",
            "483:\tlearn: 0.2321642\ttotal: 54s\tremaining: 57.5s\n",
            "484:\tlearn: 0.2321007\ttotal: 54.1s\tremaining: 57.4s\n",
            "485:\tlearn: 0.2320528\ttotal: 54.2s\tremaining: 57.3s\n",
            "486:\tlearn: 0.2319668\ttotal: 54.3s\tremaining: 57.2s\n",
            "487:\tlearn: 0.2319086\ttotal: 54.4s\tremaining: 57.1s\n",
            "488:\tlearn: 0.2318476\ttotal: 54.5s\tremaining: 57s\n",
            "489:\tlearn: 0.2318097\ttotal: 54.6s\tremaining: 56.9s\n",
            "490:\tlearn: 0.2317161\ttotal: 54.7s\tremaining: 56.7s\n",
            "491:\tlearn: 0.2316581\ttotal: 54.9s\tremaining: 56.6s\n",
            "492:\tlearn: 0.2315528\ttotal: 55s\tremaining: 56.5s\n",
            "493:\tlearn: 0.2314542\ttotal: 55.1s\tremaining: 56.4s\n",
            "494:\tlearn: 0.2313823\ttotal: 55.2s\tremaining: 56.3s\n",
            "495:\tlearn: 0.2313262\ttotal: 55.3s\tremaining: 56.2s\n",
            "496:\tlearn: 0.2312597\ttotal: 55.4s\tremaining: 56.1s\n",
            "497:\tlearn: 0.2311913\ttotal: 55.5s\tremaining: 56s\n",
            "498:\tlearn: 0.2311052\ttotal: 55.6s\tremaining: 55.9s\n",
            "499:\tlearn: 0.2309690\ttotal: 55.8s\tremaining: 55.8s\n",
            "500:\tlearn: 0.2308968\ttotal: 55.9s\tremaining: 55.6s\n",
            "501:\tlearn: 0.2308349\ttotal: 56s\tremaining: 55.5s\n",
            "502:\tlearn: 0.2307084\ttotal: 56.1s\tremaining: 55.4s\n",
            "503:\tlearn: 0.2306640\ttotal: 56.2s\tremaining: 55.3s\n",
            "504:\tlearn: 0.2305921\ttotal: 56.3s\tremaining: 55.2s\n",
            "505:\tlearn: 0.2304736\ttotal: 56.4s\tremaining: 55.1s\n",
            "506:\tlearn: 0.2304130\ttotal: 56.5s\tremaining: 55s\n",
            "507:\tlearn: 0.2303445\ttotal: 56.6s\tremaining: 54.9s\n",
            "508:\tlearn: 0.2302769\ttotal: 56.8s\tremaining: 54.8s\n",
            "509:\tlearn: 0.2301409\ttotal: 56.9s\tremaining: 54.7s\n",
            "510:\tlearn: 0.2300642\ttotal: 57s\tremaining: 54.5s\n",
            "511:\tlearn: 0.2299582\ttotal: 57.1s\tremaining: 54.4s\n",
            "512:\tlearn: 0.2299018\ttotal: 57.2s\tremaining: 54.3s\n",
            "513:\tlearn: 0.2298354\ttotal: 57.3s\tremaining: 54.2s\n",
            "514:\tlearn: 0.2297627\ttotal: 57.4s\tremaining: 54.1s\n",
            "515:\tlearn: 0.2296824\ttotal: 57.6s\tremaining: 54s\n",
            "516:\tlearn: 0.2296002\ttotal: 57.7s\tremaining: 53.9s\n",
            "517:\tlearn: 0.2295564\ttotal: 57.8s\tremaining: 53.8s\n",
            "518:\tlearn: 0.2295103\ttotal: 57.9s\tremaining: 53.7s\n",
            "519:\tlearn: 0.2294520\ttotal: 58s\tremaining: 53.5s\n",
            "520:\tlearn: 0.2293772\ttotal: 58.1s\tremaining: 53.4s\n",
            "521:\tlearn: 0.2293028\ttotal: 58.2s\tremaining: 53.3s\n",
            "522:\tlearn: 0.2292205\ttotal: 58.3s\tremaining: 53.2s\n",
            "523:\tlearn: 0.2291154\ttotal: 58.5s\tremaining: 53.1s\n",
            "524:\tlearn: 0.2290712\ttotal: 58.6s\tremaining: 53s\n",
            "525:\tlearn: 0.2289950\ttotal: 58.7s\tremaining: 52.9s\n",
            "526:\tlearn: 0.2288931\ttotal: 58.8s\tremaining: 52.8s\n",
            "527:\tlearn: 0.2288318\ttotal: 58.9s\tremaining: 52.7s\n",
            "528:\tlearn: 0.2287145\ttotal: 59s\tremaining: 52.5s\n",
            "529:\tlearn: 0.2286555\ttotal: 59.1s\tremaining: 52.4s\n",
            "530:\tlearn: 0.2285791\ttotal: 59.2s\tremaining: 52.3s\n",
            "531:\tlearn: 0.2285401\ttotal: 59.3s\tremaining: 52.2s\n",
            "532:\tlearn: 0.2284533\ttotal: 59.5s\tremaining: 52.1s\n",
            "533:\tlearn: 0.2283670\ttotal: 59.6s\tremaining: 52s\n",
            "534:\tlearn: 0.2283030\ttotal: 59.7s\tremaining: 51.9s\n",
            "535:\tlearn: 0.2282196\ttotal: 59.8s\tremaining: 51.8s\n",
            "536:\tlearn: 0.2281569\ttotal: 59.9s\tremaining: 51.6s\n",
            "537:\tlearn: 0.2280773\ttotal: 1m\tremaining: 51.5s\n",
            "538:\tlearn: 0.2280010\ttotal: 1m\tremaining: 51.4s\n",
            "539:\tlearn: 0.2279509\ttotal: 1m\tremaining: 51.3s\n",
            "540:\tlearn: 0.2278531\ttotal: 1m\tremaining: 51.2s\n",
            "541:\tlearn: 0.2277024\ttotal: 1m\tremaining: 51.1s\n",
            "542:\tlearn: 0.2276547\ttotal: 1m\tremaining: 51s\n",
            "543:\tlearn: 0.2275937\ttotal: 1m\tremaining: 50.9s\n",
            "544:\tlearn: 0.2275512\ttotal: 1m\tremaining: 50.8s\n",
            "545:\tlearn: 0.2274876\ttotal: 1m\tremaining: 50.6s\n",
            "546:\tlearn: 0.2274437\ttotal: 1m 1s\tremaining: 50.5s\n",
            "547:\tlearn: 0.2273683\ttotal: 1m 1s\tremaining: 50.4s\n",
            "548:\tlearn: 0.2272979\ttotal: 1m 1s\tremaining: 50.3s\n",
            "549:\tlearn: 0.2272245\ttotal: 1m 1s\tremaining: 50.2s\n",
            "550:\tlearn: 0.2271541\ttotal: 1m 1s\tremaining: 50.1s\n",
            "551:\tlearn: 0.2270697\ttotal: 1m 1s\tremaining: 50s\n",
            "552:\tlearn: 0.2270188\ttotal: 1m 1s\tremaining: 49.9s\n",
            "553:\tlearn: 0.2269480\ttotal: 1m 1s\tremaining: 49.7s\n",
            "554:\tlearn: 0.2268692\ttotal: 1m 1s\tremaining: 49.6s\n",
            "555:\tlearn: 0.2268334\ttotal: 1m 2s\tremaining: 49.5s\n",
            "556:\tlearn: 0.2267702\ttotal: 1m 2s\tremaining: 49.4s\n",
            "557:\tlearn: 0.2267037\ttotal: 1m 2s\tremaining: 49.3s\n",
            "558:\tlearn: 0.2266187\ttotal: 1m 2s\tremaining: 49.2s\n",
            "559:\tlearn: 0.2265614\ttotal: 1m 2s\tremaining: 49.1s\n",
            "560:\tlearn: 0.2264662\ttotal: 1m 2s\tremaining: 49s\n",
            "561:\tlearn: 0.2264233\ttotal: 1m 2s\tremaining: 48.9s\n",
            "562:\tlearn: 0.2263308\ttotal: 1m 2s\tremaining: 48.7s\n",
            "563:\tlearn: 0.2262787\ttotal: 1m 2s\tremaining: 48.6s\n",
            "564:\tlearn: 0.2261985\ttotal: 1m 3s\tremaining: 48.5s\n",
            "565:\tlearn: 0.2261292\ttotal: 1m 3s\tremaining: 48.4s\n",
            "566:\tlearn: 0.2260950\ttotal: 1m 3s\tremaining: 48.3s\n",
            "567:\tlearn: 0.2259704\ttotal: 1m 3s\tremaining: 48.2s\n",
            "568:\tlearn: 0.2258593\ttotal: 1m 3s\tremaining: 48.1s\n",
            "569:\tlearn: 0.2257945\ttotal: 1m 3s\tremaining: 48s\n",
            "570:\tlearn: 0.2257295\ttotal: 1m 3s\tremaining: 47.9s\n",
            "571:\tlearn: 0.2256682\ttotal: 1m 3s\tremaining: 47.7s\n",
            "572:\tlearn: 0.2256085\ttotal: 1m 3s\tremaining: 47.6s\n",
            "573:\tlearn: 0.2255487\ttotal: 1m 4s\tremaining: 47.5s\n",
            "574:\tlearn: 0.2254499\ttotal: 1m 4s\tremaining: 47.4s\n",
            "575:\tlearn: 0.2254071\ttotal: 1m 4s\tremaining: 47.3s\n",
            "576:\tlearn: 0.2252555\ttotal: 1m 4s\tremaining: 47.2s\n",
            "577:\tlearn: 0.2251739\ttotal: 1m 4s\tremaining: 47.1s\n",
            "578:\tlearn: 0.2251317\ttotal: 1m 4s\tremaining: 47s\n",
            "579:\tlearn: 0.2250569\ttotal: 1m 4s\tremaining: 46.8s\n",
            "580:\tlearn: 0.2249682\ttotal: 1m 4s\tremaining: 46.7s\n",
            "581:\tlearn: 0.2249095\ttotal: 1m 4s\tremaining: 46.6s\n",
            "582:\tlearn: 0.2248621\ttotal: 1m 5s\tremaining: 46.5s\n",
            "583:\tlearn: 0.2248026\ttotal: 1m 5s\tremaining: 46.4s\n",
            "584:\tlearn: 0.2247018\ttotal: 1m 5s\tremaining: 46.3s\n",
            "585:\tlearn: 0.2246585\ttotal: 1m 5s\tremaining: 46.2s\n",
            "586:\tlearn: 0.2245549\ttotal: 1m 5s\tremaining: 46.1s\n",
            "587:\tlearn: 0.2244236\ttotal: 1m 5s\tremaining: 46s\n",
            "588:\tlearn: 0.2243507\ttotal: 1m 5s\tremaining: 45.8s\n",
            "589:\tlearn: 0.2242800\ttotal: 1m 5s\tremaining: 45.7s\n",
            "590:\tlearn: 0.2242375\ttotal: 1m 5s\tremaining: 45.6s\n",
            "591:\tlearn: 0.2241746\ttotal: 1m 6s\tremaining: 45.5s\n",
            "592:\tlearn: 0.2240863\ttotal: 1m 6s\tremaining: 45.4s\n",
            "593:\tlearn: 0.2239987\ttotal: 1m 6s\tremaining: 45.3s\n",
            "594:\tlearn: 0.2239224\ttotal: 1m 6s\tremaining: 45.2s\n",
            "595:\tlearn: 0.2238543\ttotal: 1m 6s\tremaining: 45.1s\n",
            "596:\tlearn: 0.2237508\ttotal: 1m 6s\tremaining: 45s\n",
            "597:\tlearn: 0.2236525\ttotal: 1m 6s\tremaining: 44.9s\n",
            "598:\tlearn: 0.2235811\ttotal: 1m 6s\tremaining: 44.7s\n",
            "599:\tlearn: 0.2235290\ttotal: 1m 6s\tremaining: 44.6s\n",
            "600:\tlearn: 0.2234396\ttotal: 1m 7s\tremaining: 44.5s\n",
            "601:\tlearn: 0.2233444\ttotal: 1m 7s\tremaining: 44.4s\n",
            "602:\tlearn: 0.2232954\ttotal: 1m 7s\tremaining: 44.3s\n",
            "603:\tlearn: 0.2232303\ttotal: 1m 7s\tremaining: 44.2s\n",
            "604:\tlearn: 0.2231503\ttotal: 1m 7s\tremaining: 44.1s\n",
            "605:\tlearn: 0.2230975\ttotal: 1m 7s\tremaining: 44s\n",
            "606:\tlearn: 0.2230417\ttotal: 1m 7s\tremaining: 43.8s\n",
            "607:\tlearn: 0.2229371\ttotal: 1m 7s\tremaining: 43.7s\n",
            "608:\tlearn: 0.2228891\ttotal: 1m 7s\tremaining: 43.6s\n",
            "609:\tlearn: 0.2228528\ttotal: 1m 8s\tremaining: 43.5s\n",
            "610:\tlearn: 0.2228216\ttotal: 1m 8s\tremaining: 43.4s\n",
            "611:\tlearn: 0.2227678\ttotal: 1m 8s\tremaining: 43.3s\n",
            "612:\tlearn: 0.2226775\ttotal: 1m 8s\tremaining: 43.2s\n",
            "613:\tlearn: 0.2225806\ttotal: 1m 8s\tremaining: 43.1s\n",
            "614:\tlearn: 0.2225318\ttotal: 1m 8s\tremaining: 43s\n",
            "615:\tlearn: 0.2224448\ttotal: 1m 8s\tremaining: 42.9s\n",
            "616:\tlearn: 0.2223183\ttotal: 1m 8s\tremaining: 42.7s\n",
            "617:\tlearn: 0.2222525\ttotal: 1m 8s\tremaining: 42.6s\n",
            "618:\tlearn: 0.2221950\ttotal: 1m 9s\tremaining: 42.5s\n",
            "619:\tlearn: 0.2221423\ttotal: 1m 9s\tremaining: 42.4s\n",
            "620:\tlearn: 0.2220914\ttotal: 1m 9s\tremaining: 42.3s\n",
            "621:\tlearn: 0.2220651\ttotal: 1m 9s\tremaining: 42.2s\n",
            "622:\tlearn: 0.2219446\ttotal: 1m 9s\tremaining: 42.1s\n",
            "623:\tlearn: 0.2219084\ttotal: 1m 9s\tremaining: 42s\n",
            "624:\tlearn: 0.2218214\ttotal: 1m 9s\tremaining: 41.9s\n",
            "625:\tlearn: 0.2217662\ttotal: 1m 9s\tremaining: 41.7s\n",
            "626:\tlearn: 0.2217424\ttotal: 1m 9s\tremaining: 41.6s\n",
            "627:\tlearn: 0.2216766\ttotal: 1m 10s\tremaining: 41.5s\n",
            "628:\tlearn: 0.2216204\ttotal: 1m 10s\tremaining: 41.4s\n",
            "629:\tlearn: 0.2215643\ttotal: 1m 10s\tremaining: 41.3s\n",
            "630:\tlearn: 0.2215037\ttotal: 1m 10s\tremaining: 41.2s\n",
            "631:\tlearn: 0.2214136\ttotal: 1m 10s\tremaining: 41.1s\n",
            "632:\tlearn: 0.2213221\ttotal: 1m 10s\tremaining: 41s\n",
            "633:\tlearn: 0.2212289\ttotal: 1m 10s\tremaining: 40.8s\n",
            "634:\tlearn: 0.2211893\ttotal: 1m 10s\tremaining: 40.7s\n",
            "635:\tlearn: 0.2211538\ttotal: 1m 10s\tremaining: 40.6s\n",
            "636:\tlearn: 0.2211190\ttotal: 1m 11s\tremaining: 40.5s\n",
            "637:\tlearn: 0.2210783\ttotal: 1m 11s\tremaining: 40.4s\n",
            "638:\tlearn: 0.2210007\ttotal: 1m 11s\tremaining: 40.3s\n",
            "639:\tlearn: 0.2209407\ttotal: 1m 11s\tremaining: 40.2s\n",
            "640:\tlearn: 0.2209085\ttotal: 1m 11s\tremaining: 40.1s\n",
            "641:\tlearn: 0.2208506\ttotal: 1m 11s\tremaining: 40s\n",
            "642:\tlearn: 0.2207935\ttotal: 1m 11s\tremaining: 39.8s\n",
            "643:\tlearn: 0.2207492\ttotal: 1m 11s\tremaining: 39.7s\n",
            "644:\tlearn: 0.2206958\ttotal: 1m 11s\tremaining: 39.6s\n",
            "645:\tlearn: 0.2206463\ttotal: 1m 12s\tremaining: 39.5s\n",
            "646:\tlearn: 0.2205701\ttotal: 1m 12s\tremaining: 39.4s\n",
            "647:\tlearn: 0.2205285\ttotal: 1m 12s\tremaining: 39.3s\n",
            "648:\tlearn: 0.2204694\ttotal: 1m 12s\tremaining: 39.2s\n",
            "649:\tlearn: 0.2204128\ttotal: 1m 12s\tremaining: 39.1s\n",
            "650:\tlearn: 0.2203404\ttotal: 1m 12s\tremaining: 38.9s\n",
            "651:\tlearn: 0.2203093\ttotal: 1m 12s\tremaining: 38.8s\n",
            "652:\tlearn: 0.2202810\ttotal: 1m 12s\tremaining: 38.7s\n",
            "653:\tlearn: 0.2201803\ttotal: 1m 12s\tremaining: 38.6s\n",
            "654:\tlearn: 0.2201360\ttotal: 1m 13s\tremaining: 38.5s\n",
            "655:\tlearn: 0.2200972\ttotal: 1m 13s\tremaining: 38.4s\n",
            "656:\tlearn: 0.2200439\ttotal: 1m 13s\tremaining: 38.3s\n",
            "657:\tlearn: 0.2198999\ttotal: 1m 13s\tremaining: 38.2s\n",
            "658:\tlearn: 0.2198526\ttotal: 1m 13s\tremaining: 38.1s\n",
            "659:\tlearn: 0.2197942\ttotal: 1m 13s\tremaining: 37.9s\n",
            "660:\tlearn: 0.2197470\ttotal: 1m 13s\tremaining: 37.8s\n",
            "661:\tlearn: 0.2196767\ttotal: 1m 13s\tremaining: 37.7s\n",
            "662:\tlearn: 0.2196029\ttotal: 1m 13s\tremaining: 37.6s\n",
            "663:\tlearn: 0.2194905\ttotal: 1m 14s\tremaining: 37.5s\n",
            "664:\tlearn: 0.2194002\ttotal: 1m 14s\tremaining: 37.4s\n",
            "665:\tlearn: 0.2193573\ttotal: 1m 14s\tremaining: 37.3s\n",
            "666:\tlearn: 0.2193138\ttotal: 1m 14s\tremaining: 37.2s\n",
            "667:\tlearn: 0.2192802\ttotal: 1m 14s\tremaining: 37.1s\n",
            "668:\tlearn: 0.2191939\ttotal: 1m 14s\tremaining: 36.9s\n",
            "669:\tlearn: 0.2191334\ttotal: 1m 14s\tremaining: 36.8s\n",
            "670:\tlearn: 0.2190804\ttotal: 1m 14s\tremaining: 36.7s\n",
            "671:\tlearn: 0.2190472\ttotal: 1m 15s\tremaining: 36.6s\n",
            "672:\tlearn: 0.2190023\ttotal: 1m 15s\tremaining: 36.5s\n",
            "673:\tlearn: 0.2189075\ttotal: 1m 15s\tremaining: 36.4s\n",
            "674:\tlearn: 0.2188719\ttotal: 1m 15s\tremaining: 36.3s\n",
            "675:\tlearn: 0.2187672\ttotal: 1m 15s\tremaining: 36.2s\n",
            "676:\tlearn: 0.2187130\ttotal: 1m 15s\tremaining: 36.1s\n",
            "677:\tlearn: 0.2185995\ttotal: 1m 15s\tremaining: 35.9s\n",
            "678:\tlearn: 0.2185521\ttotal: 1m 15s\tremaining: 35.8s\n",
            "679:\tlearn: 0.2184886\ttotal: 1m 15s\tremaining: 35.7s\n",
            "680:\tlearn: 0.2184134\ttotal: 1m 16s\tremaining: 35.6s\n",
            "681:\tlearn: 0.2183606\ttotal: 1m 16s\tremaining: 35.5s\n",
            "682:\tlearn: 0.2183168\ttotal: 1m 16s\tremaining: 35.4s\n",
            "683:\tlearn: 0.2182722\ttotal: 1m 16s\tremaining: 35.3s\n",
            "684:\tlearn: 0.2181872\ttotal: 1m 16s\tremaining: 35.2s\n",
            "685:\tlearn: 0.2181472\ttotal: 1m 16s\tremaining: 35.1s\n",
            "686:\tlearn: 0.2181170\ttotal: 1m 16s\tremaining: 34.9s\n",
            "687:\tlearn: 0.2180767\ttotal: 1m 16s\tremaining: 34.8s\n",
            "688:\tlearn: 0.2179980\ttotal: 1m 16s\tremaining: 34.7s\n",
            "689:\tlearn: 0.2179562\ttotal: 1m 17s\tremaining: 34.6s\n",
            "690:\tlearn: 0.2178905\ttotal: 1m 17s\tremaining: 34.5s\n",
            "691:\tlearn: 0.2178496\ttotal: 1m 17s\tremaining: 34.4s\n",
            "692:\tlearn: 0.2177735\ttotal: 1m 17s\tremaining: 34.3s\n",
            "693:\tlearn: 0.2177464\ttotal: 1m 17s\tremaining: 34.2s\n",
            "694:\tlearn: 0.2177249\ttotal: 1m 17s\tremaining: 34s\n",
            "695:\tlearn: 0.2176797\ttotal: 1m 17s\tremaining: 33.9s\n",
            "696:\tlearn: 0.2176139\ttotal: 1m 17s\tremaining: 33.8s\n",
            "697:\tlearn: 0.2175122\ttotal: 1m 17s\tremaining: 33.7s\n",
            "698:\tlearn: 0.2174809\ttotal: 1m 18s\tremaining: 33.6s\n",
            "699:\tlearn: 0.2174299\ttotal: 1m 18s\tremaining: 33.5s\n",
            "700:\tlearn: 0.2173959\ttotal: 1m 18s\tremaining: 33.4s\n",
            "701:\tlearn: 0.2173487\ttotal: 1m 18s\tremaining: 33.3s\n",
            "702:\tlearn: 0.2172863\ttotal: 1m 18s\tremaining: 33.2s\n",
            "703:\tlearn: 0.2172203\ttotal: 1m 18s\tremaining: 33s\n",
            "704:\tlearn: 0.2171600\ttotal: 1m 18s\tremaining: 32.9s\n",
            "705:\tlearn: 0.2170781\ttotal: 1m 18s\tremaining: 32.8s\n",
            "706:\tlearn: 0.2169902\ttotal: 1m 18s\tremaining: 32.7s\n",
            "707:\tlearn: 0.2169137\ttotal: 1m 19s\tremaining: 32.6s\n",
            "708:\tlearn: 0.2168241\ttotal: 1m 19s\tremaining: 32.5s\n",
            "709:\tlearn: 0.2167713\ttotal: 1m 19s\tremaining: 32.4s\n",
            "710:\tlearn: 0.2167325\ttotal: 1m 19s\tremaining: 32.3s\n",
            "711:\tlearn: 0.2166920\ttotal: 1m 19s\tremaining: 32.1s\n",
            "712:\tlearn: 0.2166602\ttotal: 1m 19s\tremaining: 32s\n",
            "713:\tlearn: 0.2166418\ttotal: 1m 19s\tremaining: 31.9s\n",
            "714:\tlearn: 0.2165716\ttotal: 1m 19s\tremaining: 31.8s\n",
            "715:\tlearn: 0.2165135\ttotal: 1m 19s\tremaining: 31.7s\n",
            "716:\tlearn: 0.2164720\ttotal: 1m 20s\tremaining: 31.6s\n",
            "717:\tlearn: 0.2164119\ttotal: 1m 20s\tremaining: 31.5s\n",
            "718:\tlearn: 0.2163750\ttotal: 1m 20s\tremaining: 31.4s\n",
            "719:\tlearn: 0.2163385\ttotal: 1m 20s\tremaining: 31.3s\n",
            "720:\tlearn: 0.2163091\ttotal: 1m 20s\tremaining: 31.1s\n",
            "721:\tlearn: 0.2162478\ttotal: 1m 20s\tremaining: 31s\n",
            "722:\tlearn: 0.2162039\ttotal: 1m 20s\tremaining: 30.9s\n",
            "723:\tlearn: 0.2161264\ttotal: 1m 20s\tremaining: 30.8s\n",
            "724:\tlearn: 0.2160600\ttotal: 1m 20s\tremaining: 30.7s\n",
            "725:\tlearn: 0.2160097\ttotal: 1m 21s\tremaining: 30.6s\n",
            "726:\tlearn: 0.2159596\ttotal: 1m 21s\tremaining: 30.5s\n",
            "727:\tlearn: 0.2159136\ttotal: 1m 21s\tremaining: 30.4s\n",
            "728:\tlearn: 0.2158745\ttotal: 1m 21s\tremaining: 30.3s\n",
            "729:\tlearn: 0.2158258\ttotal: 1m 21s\tremaining: 30.1s\n",
            "730:\tlearn: 0.2157537\ttotal: 1m 21s\tremaining: 30s\n",
            "731:\tlearn: 0.2156616\ttotal: 1m 21s\tremaining: 29.9s\n",
            "732:\tlearn: 0.2156081\ttotal: 1m 21s\tremaining: 29.8s\n",
            "733:\tlearn: 0.2155598\ttotal: 1m 21s\tremaining: 29.7s\n",
            "734:\tlearn: 0.2155040\ttotal: 1m 22s\tremaining: 29.6s\n",
            "735:\tlearn: 0.2154485\ttotal: 1m 22s\tremaining: 29.5s\n",
            "736:\tlearn: 0.2153874\ttotal: 1m 22s\tremaining: 29.4s\n",
            "737:\tlearn: 0.2152994\ttotal: 1m 22s\tremaining: 29.3s\n",
            "738:\tlearn: 0.2152506\ttotal: 1m 22s\tremaining: 29.1s\n",
            "739:\tlearn: 0.2152089\ttotal: 1m 22s\tremaining: 29s\n",
            "740:\tlearn: 0.2151711\ttotal: 1m 22s\tremaining: 28.9s\n",
            "741:\tlearn: 0.2151095\ttotal: 1m 22s\tremaining: 28.8s\n",
            "742:\tlearn: 0.2150689\ttotal: 1m 22s\tremaining: 28.7s\n",
            "743:\tlearn: 0.2150045\ttotal: 1m 23s\tremaining: 28.6s\n",
            "744:\tlearn: 0.2149770\ttotal: 1m 23s\tremaining: 28.5s\n",
            "745:\tlearn: 0.2149524\ttotal: 1m 23s\tremaining: 28.4s\n",
            "746:\tlearn: 0.2148902\ttotal: 1m 23s\tremaining: 28.2s\n",
            "747:\tlearn: 0.2148346\ttotal: 1m 23s\tremaining: 28.1s\n",
            "748:\tlearn: 0.2147650\ttotal: 1m 23s\tremaining: 28s\n",
            "749:\tlearn: 0.2147333\ttotal: 1m 23s\tremaining: 27.9s\n",
            "750:\tlearn: 0.2147107\ttotal: 1m 23s\tremaining: 27.8s\n",
            "751:\tlearn: 0.2146284\ttotal: 1m 23s\tremaining: 27.7s\n",
            "752:\tlearn: 0.2145886\ttotal: 1m 24s\tremaining: 27.6s\n",
            "753:\tlearn: 0.2145294\ttotal: 1m 24s\tremaining: 27.5s\n",
            "754:\tlearn: 0.2144957\ttotal: 1m 24s\tremaining: 27.4s\n",
            "755:\tlearn: 0.2144284\ttotal: 1m 24s\tremaining: 27.2s\n",
            "756:\tlearn: 0.2143817\ttotal: 1m 24s\tremaining: 27.1s\n",
            "757:\tlearn: 0.2143156\ttotal: 1m 24s\tremaining: 27s\n",
            "758:\tlearn: 0.2142682\ttotal: 1m 24s\tremaining: 26.9s\n",
            "759:\tlearn: 0.2142126\ttotal: 1m 24s\tremaining: 26.8s\n",
            "760:\tlearn: 0.2141478\ttotal: 1m 24s\tremaining: 26.7s\n",
            "761:\tlearn: 0.2140727\ttotal: 1m 25s\tremaining: 26.6s\n",
            "762:\tlearn: 0.2140363\ttotal: 1m 25s\tremaining: 26.5s\n",
            "763:\tlearn: 0.2139831\ttotal: 1m 25s\tremaining: 26.4s\n",
            "764:\tlearn: 0.2139448\ttotal: 1m 25s\tremaining: 26.2s\n",
            "765:\tlearn: 0.2138800\ttotal: 1m 25s\tremaining: 26.1s\n",
            "766:\tlearn: 0.2138199\ttotal: 1m 25s\tremaining: 26s\n",
            "767:\tlearn: 0.2137753\ttotal: 1m 25s\tremaining: 25.9s\n",
            "768:\tlearn: 0.2137155\ttotal: 1m 25s\tremaining: 25.8s\n",
            "769:\tlearn: 0.2136486\ttotal: 1m 25s\tremaining: 25.7s\n",
            "770:\tlearn: 0.2135901\ttotal: 1m 26s\tremaining: 25.6s\n",
            "771:\tlearn: 0.2135439\ttotal: 1m 26s\tremaining: 25.5s\n",
            "772:\tlearn: 0.2134782\ttotal: 1m 26s\tremaining: 25.4s\n",
            "773:\tlearn: 0.2134317\ttotal: 1m 26s\tremaining: 25.2s\n",
            "774:\tlearn: 0.2134136\ttotal: 1m 26s\tremaining: 25.1s\n",
            "775:\tlearn: 0.2133656\ttotal: 1m 26s\tremaining: 25s\n",
            "776:\tlearn: 0.2132842\ttotal: 1m 26s\tremaining: 24.9s\n",
            "777:\tlearn: 0.2132163\ttotal: 1m 26s\tremaining: 24.8s\n",
            "778:\tlearn: 0.2131671\ttotal: 1m 27s\tremaining: 24.7s\n",
            "779:\tlearn: 0.2131036\ttotal: 1m 27s\tremaining: 24.6s\n",
            "780:\tlearn: 0.2130540\ttotal: 1m 27s\tremaining: 24.5s\n",
            "781:\tlearn: 0.2129670\ttotal: 1m 27s\tremaining: 24.4s\n",
            "782:\tlearn: 0.2129227\ttotal: 1m 27s\tremaining: 24.3s\n",
            "783:\tlearn: 0.2128550\ttotal: 1m 27s\tremaining: 24.1s\n",
            "784:\tlearn: 0.2127725\ttotal: 1m 27s\tremaining: 24s\n",
            "785:\tlearn: 0.2127268\ttotal: 1m 27s\tremaining: 23.9s\n",
            "786:\tlearn: 0.2126306\ttotal: 1m 27s\tremaining: 23.8s\n",
            "787:\tlearn: 0.2125809\ttotal: 1m 28s\tremaining: 23.7s\n",
            "788:\tlearn: 0.2125495\ttotal: 1m 28s\tremaining: 23.6s\n",
            "789:\tlearn: 0.2124908\ttotal: 1m 28s\tremaining: 23.5s\n",
            "790:\tlearn: 0.2124300\ttotal: 1m 28s\tremaining: 23.4s\n",
            "791:\tlearn: 0.2123962\ttotal: 1m 28s\tremaining: 23.2s\n",
            "792:\tlearn: 0.2123709\ttotal: 1m 28s\tremaining: 23.1s\n",
            "793:\tlearn: 0.2123510\ttotal: 1m 28s\tremaining: 23s\n",
            "794:\tlearn: 0.2123070\ttotal: 1m 28s\tremaining: 22.9s\n",
            "795:\tlearn: 0.2122734\ttotal: 1m 28s\tremaining: 22.8s\n",
            "796:\tlearn: 0.2122119\ttotal: 1m 29s\tremaining: 22.7s\n",
            "797:\tlearn: 0.2121445\ttotal: 1m 29s\tremaining: 22.6s\n",
            "798:\tlearn: 0.2121172\ttotal: 1m 29s\tremaining: 22.5s\n",
            "799:\tlearn: 0.2120709\ttotal: 1m 29s\tremaining: 22.4s\n",
            "800:\tlearn: 0.2120233\ttotal: 1m 29s\tremaining: 22.2s\n",
            "801:\tlearn: 0.2119485\ttotal: 1m 29s\tremaining: 22.1s\n",
            "802:\tlearn: 0.2118599\ttotal: 1m 29s\tremaining: 22s\n",
            "803:\tlearn: 0.2118075\ttotal: 1m 29s\tremaining: 21.9s\n",
            "804:\tlearn: 0.2117772\ttotal: 1m 29s\tremaining: 21.8s\n",
            "805:\tlearn: 0.2117167\ttotal: 1m 30s\tremaining: 21.7s\n",
            "806:\tlearn: 0.2116840\ttotal: 1m 30s\tremaining: 21.6s\n",
            "807:\tlearn: 0.2116345\ttotal: 1m 30s\tremaining: 21.5s\n",
            "808:\tlearn: 0.2115850\ttotal: 1m 30s\tremaining: 21.3s\n",
            "809:\tlearn: 0.2115318\ttotal: 1m 30s\tremaining: 21.2s\n",
            "810:\tlearn: 0.2114678\ttotal: 1m 30s\tremaining: 21.1s\n",
            "811:\tlearn: 0.2114201\ttotal: 1m 30s\tremaining: 21s\n",
            "812:\tlearn: 0.2113740\ttotal: 1m 30s\tremaining: 20.9s\n",
            "813:\tlearn: 0.2113121\ttotal: 1m 30s\tremaining: 20.8s\n",
            "814:\tlearn: 0.2112244\ttotal: 1m 31s\tremaining: 20.7s\n",
            "815:\tlearn: 0.2111582\ttotal: 1m 31s\tremaining: 20.6s\n",
            "816:\tlearn: 0.2111148\ttotal: 1m 31s\tremaining: 20.5s\n",
            "817:\tlearn: 0.2110508\ttotal: 1m 31s\tremaining: 20.3s\n",
            "818:\tlearn: 0.2109953\ttotal: 1m 31s\tremaining: 20.2s\n",
            "819:\tlearn: 0.2109560\ttotal: 1m 31s\tremaining: 20.1s\n",
            "820:\tlearn: 0.2109188\ttotal: 1m 31s\tremaining: 20s\n",
            "821:\tlearn: 0.2108663\ttotal: 1m 31s\tremaining: 19.9s\n",
            "822:\tlearn: 0.2108034\ttotal: 1m 31s\tremaining: 19.8s\n",
            "823:\tlearn: 0.2107578\ttotal: 1m 32s\tremaining: 19.7s\n",
            "824:\tlearn: 0.2107076\ttotal: 1m 32s\tremaining: 19.6s\n",
            "825:\tlearn: 0.2106345\ttotal: 1m 32s\tremaining: 19.4s\n",
            "826:\tlearn: 0.2106091\ttotal: 1m 32s\tremaining: 19.3s\n",
            "827:\tlearn: 0.2105562\ttotal: 1m 32s\tremaining: 19.2s\n",
            "828:\tlearn: 0.2105002\ttotal: 1m 32s\tremaining: 19.1s\n",
            "829:\tlearn: 0.2104389\ttotal: 1m 32s\tremaining: 19s\n",
            "830:\tlearn: 0.2103927\ttotal: 1m 32s\tremaining: 18.9s\n",
            "831:\tlearn: 0.2103015\ttotal: 1m 32s\tremaining: 18.8s\n",
            "832:\tlearn: 0.2102595\ttotal: 1m 33s\tremaining: 18.7s\n",
            "833:\tlearn: 0.2102138\ttotal: 1m 33s\tremaining: 18.6s\n",
            "834:\tlearn: 0.2101707\ttotal: 1m 33s\tremaining: 18.4s\n",
            "835:\tlearn: 0.2101385\ttotal: 1m 33s\tremaining: 18.3s\n",
            "836:\tlearn: 0.2100852\ttotal: 1m 33s\tremaining: 18.2s\n",
            "837:\tlearn: 0.2100630\ttotal: 1m 33s\tremaining: 18.1s\n",
            "838:\tlearn: 0.2100274\ttotal: 1m 33s\tremaining: 18s\n",
            "839:\tlearn: 0.2099189\ttotal: 1m 33s\tremaining: 17.9s\n",
            "840:\tlearn: 0.2098918\ttotal: 1m 34s\tremaining: 17.8s\n",
            "841:\tlearn: 0.2098439\ttotal: 1m 34s\tremaining: 17.7s\n",
            "842:\tlearn: 0.2097872\ttotal: 1m 34s\tremaining: 17.6s\n",
            "843:\tlearn: 0.2097159\ttotal: 1m 34s\tremaining: 17.4s\n",
            "844:\tlearn: 0.2096709\ttotal: 1m 34s\tremaining: 17.3s\n",
            "845:\tlearn: 0.2096331\ttotal: 1m 34s\tremaining: 17.2s\n",
            "846:\tlearn: 0.2095773\ttotal: 1m 34s\tremaining: 17.1s\n",
            "847:\tlearn: 0.2095307\ttotal: 1m 34s\tremaining: 17s\n",
            "848:\tlearn: 0.2095051\ttotal: 1m 34s\tremaining: 16.9s\n",
            "849:\tlearn: 0.2094795\ttotal: 1m 35s\tremaining: 16.8s\n",
            "850:\tlearn: 0.2094468\ttotal: 1m 35s\tremaining: 16.7s\n",
            "851:\tlearn: 0.2093929\ttotal: 1m 35s\tremaining: 16.5s\n",
            "852:\tlearn: 0.2093258\ttotal: 1m 35s\tremaining: 16.4s\n",
            "853:\tlearn: 0.2092836\ttotal: 1m 35s\tremaining: 16.3s\n",
            "854:\tlearn: 0.2092530\ttotal: 1m 35s\tremaining: 16.2s\n",
            "855:\tlearn: 0.2091946\ttotal: 1m 35s\tremaining: 16.1s\n",
            "856:\tlearn: 0.2091272\ttotal: 1m 35s\tremaining: 16s\n",
            "857:\tlearn: 0.2090620\ttotal: 1m 35s\tremaining: 15.9s\n",
            "858:\tlearn: 0.2090261\ttotal: 1m 36s\tremaining: 15.8s\n",
            "859:\tlearn: 0.2089687\ttotal: 1m 36s\tremaining: 15.7s\n",
            "860:\tlearn: 0.2088710\ttotal: 1m 36s\tremaining: 15.5s\n",
            "861:\tlearn: 0.2088471\ttotal: 1m 36s\tremaining: 15.4s\n",
            "862:\tlearn: 0.2087808\ttotal: 1m 36s\tremaining: 15.3s\n",
            "863:\tlearn: 0.2087379\ttotal: 1m 36s\tremaining: 15.2s\n",
            "864:\tlearn: 0.2086756\ttotal: 1m 36s\tremaining: 15.1s\n",
            "865:\tlearn: 0.2086217\ttotal: 1m 36s\tremaining: 15s\n",
            "866:\tlearn: 0.2085648\ttotal: 1m 36s\tremaining: 14.9s\n",
            "867:\tlearn: 0.2085106\ttotal: 1m 37s\tremaining: 14.8s\n",
            "868:\tlearn: 0.2084792\ttotal: 1m 37s\tremaining: 14.6s\n",
            "869:\tlearn: 0.2084097\ttotal: 1m 37s\tremaining: 14.5s\n",
            "870:\tlearn: 0.2083665\ttotal: 1m 37s\tremaining: 14.4s\n",
            "871:\tlearn: 0.2083218\ttotal: 1m 37s\tremaining: 14.3s\n",
            "872:\tlearn: 0.2082918\ttotal: 1m 37s\tremaining: 14.2s\n",
            "873:\tlearn: 0.2082515\ttotal: 1m 37s\tremaining: 14.1s\n",
            "874:\tlearn: 0.2082033\ttotal: 1m 37s\tremaining: 14s\n",
            "875:\tlearn: 0.2081619\ttotal: 1m 37s\tremaining: 13.9s\n",
            "876:\tlearn: 0.2080864\ttotal: 1m 38s\tremaining: 13.8s\n",
            "877:\tlearn: 0.2080435\ttotal: 1m 38s\tremaining: 13.6s\n",
            "878:\tlearn: 0.2080020\ttotal: 1m 38s\tremaining: 13.5s\n",
            "879:\tlearn: 0.2079567\ttotal: 1m 38s\tremaining: 13.4s\n",
            "880:\tlearn: 0.2079229\ttotal: 1m 38s\tremaining: 13.3s\n",
            "881:\tlearn: 0.2078641\ttotal: 1m 38s\tremaining: 13.2s\n",
            "882:\tlearn: 0.2078268\ttotal: 1m 38s\tremaining: 13.1s\n",
            "883:\tlearn: 0.2077759\ttotal: 1m 38s\tremaining: 13s\n",
            "884:\tlearn: 0.2077406\ttotal: 1m 38s\tremaining: 12.9s\n",
            "885:\tlearn: 0.2077015\ttotal: 1m 39s\tremaining: 12.7s\n",
            "886:\tlearn: 0.2076611\ttotal: 1m 39s\tremaining: 12.6s\n",
            "887:\tlearn: 0.2075606\ttotal: 1m 39s\tremaining: 12.5s\n",
            "888:\tlearn: 0.2075170\ttotal: 1m 39s\tremaining: 12.4s\n",
            "889:\tlearn: 0.2074664\ttotal: 1m 39s\tremaining: 12.3s\n",
            "890:\tlearn: 0.2074313\ttotal: 1m 39s\tremaining: 12.2s\n",
            "891:\tlearn: 0.2073883\ttotal: 1m 39s\tremaining: 12.1s\n",
            "892:\tlearn: 0.2073412\ttotal: 1m 39s\tremaining: 12s\n",
            "893:\tlearn: 0.2073129\ttotal: 1m 39s\tremaining: 11.8s\n",
            "894:\tlearn: 0.2072644\ttotal: 1m 40s\tremaining: 11.7s\n",
            "895:\tlearn: 0.2072185\ttotal: 1m 40s\tremaining: 11.6s\n",
            "896:\tlearn: 0.2072052\ttotal: 1m 40s\tremaining: 11.5s\n",
            "897:\tlearn: 0.2071510\ttotal: 1m 40s\tremaining: 11.4s\n",
            "898:\tlearn: 0.2071131\ttotal: 1m 40s\tremaining: 11.3s\n",
            "899:\tlearn: 0.2070809\ttotal: 1m 40s\tremaining: 11.2s\n",
            "900:\tlearn: 0.2070471\ttotal: 1m 40s\tremaining: 11.1s\n",
            "901:\tlearn: 0.2070079\ttotal: 1m 40s\tremaining: 11s\n",
            "902:\tlearn: 0.2069141\ttotal: 1m 40s\tremaining: 10.8s\n",
            "903:\tlearn: 0.2068607\ttotal: 1m 41s\tremaining: 10.7s\n",
            "904:\tlearn: 0.2068082\ttotal: 1m 41s\tremaining: 10.6s\n",
            "905:\tlearn: 0.2067438\ttotal: 1m 41s\tremaining: 10.5s\n",
            "906:\tlearn: 0.2067036\ttotal: 1m 41s\tremaining: 10.4s\n",
            "907:\tlearn: 0.2066682\ttotal: 1m 41s\tremaining: 10.3s\n",
            "908:\tlearn: 0.2066294\ttotal: 1m 41s\tremaining: 10.2s\n",
            "909:\tlearn: 0.2066020\ttotal: 1m 41s\tremaining: 10.1s\n",
            "910:\tlearn: 0.2065318\ttotal: 1m 41s\tremaining: 9.95s\n",
            "911:\tlearn: 0.2064983\ttotal: 1m 41s\tremaining: 9.84s\n",
            "912:\tlearn: 0.2064500\ttotal: 1m 42s\tremaining: 9.73s\n",
            "913:\tlearn: 0.2064140\ttotal: 1m 42s\tremaining: 9.61s\n",
            "914:\tlearn: 0.2063856\ttotal: 1m 42s\tremaining: 9.5s\n",
            "915:\tlearn: 0.2063619\ttotal: 1m 42s\tremaining: 9.39s\n",
            "916:\tlearn: 0.2063121\ttotal: 1m 42s\tremaining: 9.28s\n",
            "917:\tlearn: 0.2062756\ttotal: 1m 42s\tremaining: 9.17s\n",
            "918:\tlearn: 0.2062376\ttotal: 1m 42s\tremaining: 9.06s\n",
            "919:\tlearn: 0.2062176\ttotal: 1m 42s\tremaining: 8.94s\n",
            "920:\tlearn: 0.2061523\ttotal: 1m 42s\tremaining: 8.83s\n",
            "921:\tlearn: 0.2061300\ttotal: 1m 43s\tremaining: 8.72s\n",
            "922:\tlearn: 0.2060711\ttotal: 1m 43s\tremaining: 8.61s\n",
            "923:\tlearn: 0.2060288\ttotal: 1m 43s\tremaining: 8.5s\n",
            "924:\tlearn: 0.2059906\ttotal: 1m 43s\tremaining: 8.38s\n",
            "925:\tlearn: 0.2059648\ttotal: 1m 43s\tremaining: 8.27s\n",
            "926:\tlearn: 0.2059163\ttotal: 1m 43s\tremaining: 8.16s\n",
            "927:\tlearn: 0.2058686\ttotal: 1m 43s\tremaining: 8.05s\n",
            "928:\tlearn: 0.2058294\ttotal: 1m 43s\tremaining: 7.94s\n",
            "929:\tlearn: 0.2057861\ttotal: 1m 43s\tremaining: 7.83s\n",
            "930:\tlearn: 0.2057541\ttotal: 1m 44s\tremaining: 7.71s\n",
            "931:\tlearn: 0.2056956\ttotal: 1m 44s\tremaining: 7.6s\n",
            "932:\tlearn: 0.2056751\ttotal: 1m 44s\tremaining: 7.49s\n",
            "933:\tlearn: 0.2056328\ttotal: 1m 44s\tremaining: 7.38s\n",
            "934:\tlearn: 0.2055913\ttotal: 1m 44s\tremaining: 7.27s\n",
            "935:\tlearn: 0.2055610\ttotal: 1m 44s\tremaining: 7.16s\n",
            "936:\tlearn: 0.2055355\ttotal: 1m 44s\tremaining: 7.04s\n",
            "937:\tlearn: 0.2054934\ttotal: 1m 44s\tremaining: 6.93s\n",
            "938:\tlearn: 0.2054351\ttotal: 1m 45s\tremaining: 6.82s\n",
            "939:\tlearn: 0.2053823\ttotal: 1m 45s\tremaining: 6.71s\n",
            "940:\tlearn: 0.2053417\ttotal: 1m 45s\tremaining: 6.6s\n",
            "941:\tlearn: 0.2052941\ttotal: 1m 45s\tremaining: 6.49s\n",
            "942:\tlearn: 0.2052434\ttotal: 1m 45s\tremaining: 6.37s\n",
            "943:\tlearn: 0.2052112\ttotal: 1m 45s\tremaining: 6.26s\n",
            "944:\tlearn: 0.2051772\ttotal: 1m 45s\tremaining: 6.15s\n",
            "945:\tlearn: 0.2051207\ttotal: 1m 45s\tremaining: 6.04s\n",
            "946:\tlearn: 0.2050823\ttotal: 1m 45s\tremaining: 5.93s\n",
            "947:\tlearn: 0.2050475\ttotal: 1m 46s\tremaining: 5.82s\n",
            "948:\tlearn: 0.2050085\ttotal: 1m 46s\tremaining: 5.7s\n",
            "949:\tlearn: 0.2049576\ttotal: 1m 46s\tremaining: 5.59s\n",
            "950:\tlearn: 0.2049231\ttotal: 1m 46s\tremaining: 5.48s\n",
            "951:\tlearn: 0.2048942\ttotal: 1m 46s\tremaining: 5.37s\n",
            "952:\tlearn: 0.2048450\ttotal: 1m 46s\tremaining: 5.26s\n",
            "953:\tlearn: 0.2048062\ttotal: 1m 46s\tremaining: 5.14s\n",
            "954:\tlearn: 0.2047613\ttotal: 1m 46s\tremaining: 5.03s\n",
            "955:\tlearn: 0.2047004\ttotal: 1m 46s\tremaining: 4.92s\n",
            "956:\tlearn: 0.2046586\ttotal: 1m 47s\tremaining: 4.81s\n",
            "957:\tlearn: 0.2046309\ttotal: 1m 47s\tremaining: 4.7s\n",
            "958:\tlearn: 0.2045715\ttotal: 1m 47s\tremaining: 4.58s\n",
            "959:\tlearn: 0.2045323\ttotal: 1m 47s\tremaining: 4.47s\n",
            "960:\tlearn: 0.2044970\ttotal: 1m 47s\tremaining: 4.36s\n",
            "961:\tlearn: 0.2044619\ttotal: 1m 47s\tremaining: 4.25s\n",
            "962:\tlearn: 0.2043982\ttotal: 1m 47s\tremaining: 4.14s\n",
            "963:\tlearn: 0.2043450\ttotal: 1m 47s\tremaining: 4.03s\n",
            "964:\tlearn: 0.2043133\ttotal: 1m 47s\tremaining: 3.91s\n",
            "965:\tlearn: 0.2042850\ttotal: 1m 48s\tremaining: 3.8s\n",
            "966:\tlearn: 0.2042300\ttotal: 1m 48s\tremaining: 3.69s\n",
            "967:\tlearn: 0.2041726\ttotal: 1m 48s\tremaining: 3.58s\n",
            "968:\tlearn: 0.2041327\ttotal: 1m 48s\tremaining: 3.47s\n",
            "969:\tlearn: 0.2040677\ttotal: 1m 48s\tremaining: 3.35s\n",
            "970:\tlearn: 0.2040361\ttotal: 1m 48s\tremaining: 3.24s\n",
            "971:\tlearn: 0.2039924\ttotal: 1m 48s\tremaining: 3.13s\n",
            "972:\tlearn: 0.2039389\ttotal: 1m 48s\tremaining: 3.02s\n",
            "973:\tlearn: 0.2038729\ttotal: 1m 48s\tremaining: 2.91s\n",
            "974:\tlearn: 0.2038375\ttotal: 1m 49s\tremaining: 2.8s\n",
            "975:\tlearn: 0.2038031\ttotal: 1m 49s\tremaining: 2.68s\n",
            "976:\tlearn: 0.2037819\ttotal: 1m 49s\tremaining: 2.57s\n",
            "977:\tlearn: 0.2037192\ttotal: 1m 49s\tremaining: 2.46s\n",
            "978:\tlearn: 0.2036140\ttotal: 1m 49s\tremaining: 2.35s\n",
            "979:\tlearn: 0.2035821\ttotal: 1m 49s\tremaining: 2.24s\n",
            "980:\tlearn: 0.2035233\ttotal: 1m 49s\tremaining: 2.13s\n",
            "981:\tlearn: 0.2034754\ttotal: 1m 49s\tremaining: 2.01s\n",
            "982:\tlearn: 0.2034373\ttotal: 1m 49s\tremaining: 1.9s\n",
            "983:\tlearn: 0.2033831\ttotal: 1m 50s\tremaining: 1.79s\n",
            "984:\tlearn: 0.2033595\ttotal: 1m 50s\tremaining: 1.68s\n",
            "985:\tlearn: 0.2033279\ttotal: 1m 50s\tremaining: 1.57s\n",
            "986:\tlearn: 0.2032828\ttotal: 1m 50s\tremaining: 1.45s\n",
            "987:\tlearn: 0.2032321\ttotal: 1m 50s\tremaining: 1.34s\n",
            "988:\tlearn: 0.2031962\ttotal: 1m 50s\tremaining: 1.23s\n",
            "989:\tlearn: 0.2031619\ttotal: 1m 50s\tremaining: 1.12s\n",
            "990:\tlearn: 0.2031285\ttotal: 1m 50s\tremaining: 1.01s\n",
            "991:\tlearn: 0.2030537\ttotal: 1m 51s\tremaining: 895ms\n",
            "992:\tlearn: 0.2030299\ttotal: 1m 51s\tremaining: 783ms\n",
            "993:\tlearn: 0.2029961\ttotal: 1m 51s\tremaining: 671ms\n",
            "994:\tlearn: 0.2029516\ttotal: 1m 51s\tremaining: 560ms\n",
            "995:\tlearn: 0.2028851\ttotal: 1m 51s\tremaining: 448ms\n",
            "996:\tlearn: 0.2028406\ttotal: 1m 51s\tremaining: 336ms\n",
            "997:\tlearn: 0.2028017\ttotal: 1m 51s\tremaining: 224ms\n",
            "998:\tlearn: 0.2027668\ttotal: 1m 51s\tremaining: 112ms\n",
            "999:\tlearn: 0.2027321\ttotal: 1m 51s\tremaining: 0us\n",
            "train 0.42540775345672843\n",
            "test 0.3352253139644755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhv8c1DGisou",
        "colab_type": "text"
      },
      "source": [
        "just try to use XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpziTyzeh1Od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1e6630fa-54a4-4335-9ef0-27ade9061a0d"
      },
      "source": [
        "import xgboost\n",
        "from xgboost import XGBClassifier as xgb\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est',  xgb())\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.39326124218078107\n",
            "test 0.3353187957066505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcuMsFj0timy",
        "colab_type": "code",
        "outputId": "f054f694-c3bc-4741-c3f6-b753a5dd955d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%%time\n",
        "# baseline 2 \n",
        "# pos features + one hot encoding + logistic regression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "\n",
        "model = Pipeline([\n",
        "    ('enc', OneHotEncoder()),\n",
        "    ('est',RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = SEED))\n",
        "    #('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
        "    #                         penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
        "])\n",
        "\n",
        "model.fit(df_train[columns], y_train)\n",
        "\n",
        "print('score to beat - 0.3966')\n",
        "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score to beat - 0.3966\n",
            "train 0.7425836587782345\n",
            "test 0.5863944082579811\n",
            "CPU times: user 2.54 s, sys: 11 ms, total: 2.56 s\n",
            "Wall time: 2.56 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEJXgecYtinb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7e366cbb-d544-4145-a5e9-4165b93f5815"
      },
      "source": [
        "%%time\n",
        "# baseline 3\n",
        "# use word2vec cbow embedding + baseline 2 + svm\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.svm import LinearSVC\n",
        "import scipy.sparse as sp\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "X_train = sp.hstack([\n",
        "    embeding.transform(df_train.word),\n",
        "    embeding.transform(df_train['next-word']),\n",
        "    embeding.transform(df_train['next-next-word']),\n",
        "    embeding.transform(df_train['prev-word']),\n",
        "    embeding.transform(df_train['prev-prev-word']),\n",
        "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "X_test = sp.hstack([\n",
        "    embeding.transform(df_test.word),\n",
        "    embeding.transform(df_test['next-word']),\n",
        "    embeding.transform(df_test['next-next-word']),\n",
        "    embeding.transform(df_test['prev-word']),\n",
        "    embeding.transform(df_test['prev-prev-word']),\n",
        "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
        "])\n",
        "\n",
        "# model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
        "#                                    {'C': np.logspace(-4, 0, 5)}, \n",
        "#                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
        "\n",
        "model = Pipeline([\n",
        "    ('est',RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = SEED))\n",
        "])\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.9884754844600314\n",
            "test 0.8206240392482764\n",
            "CPU times: user 1min 11s, sys: 656 ms, total: 1min 11s\n",
            "Wall time: 1min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcgJNEo4FB7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
        "#model = Pipeline([('est', xgb())])\n",
        "\n",
        "#model.fit(X_train, y_train)\n",
        "#print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
        "#print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAw4JsLMM_EY",
        "colab_type": "text"
      },
      "source": [
        "*try to create new feature 'upper_case'*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IsKaCy3FZOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = df\n",
        "\n",
        "# add label 'upper_case' wheter word starts with upper case letter\n",
        "\n",
        "test_df['upper_case'] = [1 if item[0].isupper() else 0 for item in test_df['word']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGNa46LKxl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "67edca53-e2ad-47b1-cf96-986f423fa503"
      },
      "source": [
        "# encode categorial variables\n",
        "\n",
        "le = LabelEncoder()\n",
        "test_df['pos'] = le.fit_transform(df.pos)\n",
        "test_df['next-pos'] = le.fit_transform(df['next-pos'])\n",
        "test_df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
        "test_df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
        "test_df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])\n",
        "test_df['upper_case'] = le.fit_transform(df['upper_case'])\n",
        "# splitting\n",
        "test_y = LabelEncoder().fit_transform(test_df.tag)\n",
        "\n",
        "test_df_train, test_df_test, test_y_train, test_y_test = model_selection.train_test_split(test_df, test_y, stratify=test_y, \n",
        "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
        "print('train', df_train.shape[0])\n",
        "print('test', df_test.shape[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 50155\n",
            "test 16719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqak-MMcLMiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "9300308d-6a4c-458d-f853-8036f7b5dc18"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_idx</th>\n",
              "      <th>next-next-pos</th>\n",
              "      <th>next-next-word</th>\n",
              "      <th>next-pos</th>\n",
              "      <th>next-word</th>\n",
              "      <th>pos</th>\n",
              "      <th>prev-pos</th>\n",
              "      <th>prev-prev-pos</th>\n",
              "      <th>prev-prev-word</th>\n",
              "      <th>prev-word</th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>length</th>\n",
              "      <th>upper_case</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>__START2__</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>39</td>\n",
              "      <td>__START1__</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>have</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>marched</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>of</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>16</td>\n",
              "      <td>London</td>\n",
              "      <td>9</td>\n",
              "      <td>through</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>18</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>have</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66869</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>15</td>\n",
              "      <td>back</td>\n",
              "      <td>10</td>\n",
              "      <td>serious</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>hospitalized</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66870</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>15</td>\n",
              "      <td>injury</td>\n",
              "      <td>15</td>\n",
              "      <td>back</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>serious</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66871</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>2</td>\n",
              "      <td>.</td>\n",
              "      <td>15</td>\n",
              "      <td>injury</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>a</td>\n",
              "      <td>serious</td>\n",
              "      <td>back</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66872</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>39</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>2</td>\n",
              "      <td>.</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>serious</td>\n",
              "      <td>back</td>\n",
              "      <td>injury</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66873</th>\n",
              "      <td>1500.0</td>\n",
              "      <td>40</td>\n",
              "      <td>__END2__</td>\n",
              "      <td>39</td>\n",
              "      <td>__END1__</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>back</td>\n",
              "      <td>injury</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>66874 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_idx  next-next-pos next-next-word  ...  tag length  upper_case\n",
              "0               1.0             18  demonstrators  ...    O     48           1\n",
              "1               1.0             33           have  ...    O     48           0\n",
              "2               1.0             32        marched  ...    O     48           0\n",
              "3               1.0              9        through  ...    O     48           0\n",
              "4               1.0             16         London  ...    O     48           0\n",
              "...             ...            ...            ...  ...  ...    ...         ...\n",
              "66869        1500.0             15           back  ...    O     30           0\n",
              "66870        1500.0             15         injury  ...    O     30           0\n",
              "66871        1500.0              2              .  ...    O     30           0\n",
              "66872        1500.0             39       __END1__  ...    O     30           0\n",
              "66873        1500.0             40       __END2__  ...    O     30           0\n",
              "\n",
              "[66874 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL5G029lJ41I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c69d5de9-e315-4b76-b529-041945ab1013"
      },
      "source": [
        "%%time\n",
        "\n",
        "embeding = w2v_cbow\n",
        "encoder_pos = OneHotEncoder()\n",
        "test_X_train = sp.hstack([\n",
        "    embeding.transform(test_df_train.word),\n",
        "    embeding.transform(test_df_train['next-word']),\n",
        "    embeding.transform(test_df_train['next-next-word']),\n",
        "    embeding.transform(test_df_train['prev-word']),\n",
        "    embeding.transform(test_df_train['prev-prev-word']),\n",
        "    encoder_pos.fit_transform(test_df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos', 'upper_case']])\n",
        "])\n",
        "test_X_test = sp.hstack([\n",
        "    embeding.transform(test_df_test.word),\n",
        "    embeding.transform(test_df_test['next-word']),\n",
        "    embeding.transform(test_df_test['next-next-word']),\n",
        "    embeding.transform(test_df_test['prev-word']),\n",
        "    embeding.transform(test_df_test['prev-prev-word']),\n",
        "    encoder_pos.transform(test_df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos', 'upper_case']])\n",
        "])\n",
        "\n",
        "model = Pipeline([\n",
        "    ('est',RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = SEED))\n",
        "])\n",
        "model.fit(test_X_train, test_y_train)\n",
        "\n",
        "print('train', metrics.f1_score(test_y_train, model.predict(test_X_train), average='macro'))\n",
        "print('test', metrics.f1_score(test_y_test, model.predict(test_X_test), average='macro'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train 0.9892644329152468\n",
            "test 0.8404846501913203\n",
            "CPU times: user 1min 1s, sys: 344 ms, total: 1min 1s\n",
            "Wall time: 1min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLaGIOjxL2SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}